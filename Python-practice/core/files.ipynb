{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\DATA SCIENCE\\\\Data Science Master\\\\Python-practice\\\\core'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is 8E14-CDAD\n",
      "\n",
      " Directory of d:\\DATA SCIENCE\\Data Science Master\\Python-practice\\core\n",
      "\n",
      "04-02-2024  05:20    <DIR>          .\n",
      "08-01-2024  19:09    <DIR>          ..\n",
      "04-02-2024  18:35             1,016 files.ipynb\n",
      "10-01-2024  02:35            13,258 function_all.ipynb\n",
      "09-01-2024  03:08            13,243 live-lecture.ipynb\n",
      "21-01-2024  20:22            23,364 Oops.ipynb\n",
      "               4 File(s)         50,881 bytes\n",
      "               2 Dir(s)  519,327,432,704 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('test.txt','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "802"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\" i am damodar , eren , mikasa ,levi .Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. This course will be taught in Hindi language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" i am damodar , eren , mikasa ,levi .Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. This course will be taught in Hindi language.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('test.txt','r') \n",
    "data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first \n",
      "after seek    i am damodar , eren , mikasa ,levi .Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. This course will be taught in Hindi language.\n"
     ]
    }
   ],
   "source": [
    "# `data.seek(0)` is used to move the file pointer to the beginning of the file. This allows you to read the file from the start or overwrite the existing content.\n",
    "print('first' , data.read())\n",
    "data.seek(0)\n",
    "print('after seek  ' ,data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i am damodar , eren , mikasa ,levi .Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. This course will be taught in Hindi language.\n"
     ]
    }
   ],
   "source": [
    "data.seek(0)\n",
    "for line in data:\n",
    "    print(line)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line `import os` is importing the `os` module in Python. The `os` module provides a way to use operating system dependent functionality, such as reading or writing to the file system, accessing environment variables, and executing system commands.\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "802"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text you've provided, \"os basic commands\", seems to refer to the `os` module in Python, which provides a way of using operating system dependent functionality. Here are some basic commands:\n",
    "\n",
    "1. **Importing the module**: To use the `os` module, you first need to import it.\n",
    "\n",
    "    ```python\n",
    "    import os\n",
    "    ```\n",
    "\n",
    "2. **Getting the current working directory**: You can use `os.getcwd()` to get the current working directory.\n",
    "\n",
    "    ```python\n",
    "    print(os.getcwd())\n",
    "    ```\n",
    "\n",
    "3. **Changing the current working directory**: You can use `os.chdir(path)` to change the current working directory.\n",
    "\n",
    "    ```python\n",
    "    os.chdir('/path/to/your/directory')\n",
    "    ```\n",
    "\n",
    "4. **Listing files and directories**: You can use `os.listdir(path)` to get a list of all files and directories in the specified directory.\n",
    "\n",
    "    ```python\n",
    "    print(os.listdir('/path/to/your/directory'))\n",
    "    ```\n",
    "\n",
    "5. **Creating a new directory**: You can use `os.mkdir(path)` to create a new directory.\n",
    "\n",
    "    ```python\n",
    "    os.mkdir('/path/to/your/new/directory')\n",
    "    ```\n",
    "\n",
    "6. **Renaming a file or directory**: You can use `os.rename(src, dst)` to rename a file or directory from `src` to `dst`.\n",
    "\n",
    "    ```python\n",
    "    os.rename('/path/to/old/name', '/path/to/new/name')\n",
    "    ```\n",
    "\n",
    "7. **Removing a file**: You can use `os.remove(path)` to remove (delete) a file.\n",
    "\n",
    "    ```python\n",
    "    os.remove('/path/to/the/file')\n",
    "    ```\n",
    "\n",
    "8. **Removing a directory**: You can use `os.rmdir(path)` to remove (delete) a directory. Note that the directory must be empty.\n",
    "\n",
    "    ```python\n",
    "    os.rmdir('/path/to/the/directory')\n",
    "    ```\n",
    "\n",
    "The `os` module in Python provides functions for interacting with the operating system. Here are some more commands:\n",
    "\n",
    "9. **Checking if a path exists**: You can use `os.path.exists(path)` to check if a certain path exists.\n",
    "\n",
    "    ```python\n",
    "    if os.path.exists('/path/to/the/directory'):\n",
    "        print(\"Directory exists\")\n",
    "    else:\n",
    "        print(\"Directory does not exist\")\n",
    "    ```\n",
    "\n",
    "10. **Checking if a path is a file**: You can use `os.path.isfile(path)` to check if a certain path is a file.\n",
    "\n",
    "    ```python\n",
    "    if os.path.isfile('/path/to/the/file'):\n",
    "        print(\"It is a file\")\n",
    "    else:\n",
    "        print(\"It is not a file\")\n",
    "    ```\n",
    "\n",
    "11. **Checking if a path is a directory**: You can use `os.path.isdir(path)` to check if a certain path is a directory.\n",
    "\n",
    "    ```python\n",
    "    if os.path.isdir('/path/to/the/directory'):\n",
    "        print(\"It is a directory\")\n",
    "    else:\n",
    "        print(\"It is not a directory\")\n",
    "    ```\n",
    "\n",
    "12. **Getting the size of a file**: You can use `os.path.getsize(path)` to get the size of a file in bytes.\n",
    "\n",
    "    ```python\n",
    "    size = os.path.getsize('/path/to/the/file')\n",
    "    print(f\"The size of the file is {size} bytes\")\n",
    "    ```\n",
    "\n",
    "13. **Joining paths**: You can use `os.path.join(path1, path2, ...)` to join one or more path components intelligently.\n",
    "\n",
    "    ```python\n",
    "    full_path = os.path.join('/path/to/the/directory', 'file.txt')\n",
    "    print(full_path)  # Outputs: /path/to/the/directory/file.txt\n",
    "    ```\n",
    "\n",
    "14. **Splitting a path**: You can use `os.path.split(path)` to split a pathname. The function returns `(head, tail)` where `tail` is the last pathname component and `head` is everything leading up to that.\n",
    "\n",
    "    ```python\n",
    "    head, tail = os.path.split('/path/to/the/directory/file.txt')\n",
    "    print(head)  # Outputs: /path/to/the/directory\n",
    "    print(tail)  # Outputs: file.txt\n",
    "    ```\n",
    "\n",
    "15. **Getting the file extension**: You can use `os.path.splitext(path)` to split the pathname path into a pair `(root, ext)` such that `root + ext == path`, and `ext` is empty or begins with a period and contains at most one period.\n",
    "\n",
    "    ```python\n",
    "    root, ext = os.path.splitext('/path/to/the/file.txt')\n",
    "    print(root)  # Outputs: /path/to/the/file\n",
    "    print(ext)  # Outputs: .txt\n",
    "    ```\n",
    "\n",
    "Remember to replace '/path/to/the/directory' and other paths with your actual file or directory paths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DATA SCIENCE\\Data Science Master\\Python-practice\\core\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../modules/package')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DATA SCIENCE\\Data Science Master\\Python-practice\\modules\\package\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DATA SCIENCE\\Data Science Master\\Python-practice\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['core', 'modules', 'Pandas', 'threading']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\DATA SCIENCE\\\\Data Science Master\\\\Python-practice\\\\core'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files.ipynb',\n",
       " 'function_all.ipynb',\n",
       " 'live-lecture.ipynb',\n",
       " 'Oops.ipynb',\n",
       " 'test',\n",
       " 'test.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('test','test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files.ipynb',\n",
       " 'function_all.ipynb',\n",
       " 'live-lecture.ipynb',\n",
       " 'Oops.ipynb',\n",
       " 'test.txt',\n",
       " 'test1']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "\n",
    "# Change the file permissions to allow deletion\n",
    "ctypes.windll.shell32.ShellExecuteW(None, \"runas\", \"python\", f\"-c \\\"import os; os.remove('test1')\\\"\", None, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `import shutil` is importing the `shutil` module in Python. The `shutil` module provides a higher-level interface for file operations, such as copying, moving, and deleting files and directories.\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test1.txt'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy('test.txt','test1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shutil` module in Python provides high-level file operations. Here are some basic commands:\n",
    "\n",
    "1. **Copy a file**: You can use `shutil.copy(src, dst)` to copy the file `src` to the file or directory `dst`.\n",
    "\n",
    "    ```python\n",
    "    shutil.copy('/path/to/source/file', '/path/to/destination')\n",
    "    ```\n",
    "\n",
    "2. **Copy a directory**: You can use `shutil.copytree(src, dst)` to recursively copy an entire directory tree rooted at `src` to a directory named `dst` and return the destination directory.\n",
    "\n",
    "    ```python\n",
    "    shutil.copytree('/path/to/source/directory', '/path/to/destination/directory')\n",
    "    ```\n",
    "\n",
    "3. **Move a file or directory**: You can use `shutil.move(src, dst)` to move the file or directory `src` to `dst`.\n",
    "\n",
    "    ```python\n",
    "    shutil.move('/path/to/source/file', '/path/to/destination')\n",
    "    ```\n",
    "\n",
    "4. **Delete a directory**: You can use `shutil.rmtree(path)` to delete an entire directory tree; `path` must point to a directory (but not a symbolic link to a directory).\n",
    "\n",
    "    ```python\n",
    "    shutil.rmtree('/path/to/the/directory')\n",
    "    ```\n",
    "\n",
    "5. **Archive files**: You can use `shutil.make_archive(base_name, format, root_dir)` to create an archive file (such as zip or tar).\n",
    "\n",
    "    ```python\n",
    "    shutil.make_archive('archive_name', 'zip', '/path/to/directory')\n",
    "    ```\n",
    "\n",
    "6. **Unpack archive**: You can use `shutil.unpack_archive(filename, extract_dir)` to unpack an archive file.\n",
    "\n",
    "    ```python\n",
    "    shutil.unpack_archive('archive.zip', '/path/to/extract/location')\n",
    "    ```\n",
    "\n",
    "7. **Copy file metadata**: You can use `shutil.copystat(src, dst)` to copy the permission bits, last access time, last modification time, and flags from `src` to `dst`.\n",
    "\n",
    "    ```python\n",
    "    shutil.copystat('/path/to/source/file', '/path/to/destination/file')\n",
    "    ```\n",
    "\n",
    "8. **Copy file and metadata**: You can use `shutil.copy2(src, dst)` to copy the file `src` to the file or directory `dst` and also attempts to copy the fileâ€™s metadata.\n",
    "\n",
    "    ```python\n",
    "    shutil.copy2('/path/to/source/file', '/path/to/destination')\n",
    "    ```\n",
    "\n",
    "9. **Disk usage**: You can use `shutil.disk_usage(path)` to return disk usage statistics about the given path as a named tuple with the attributes total, used and free, which are the amount of total, used and free space, in bytes.\n",
    "\n",
    "    ```python\n",
    "    print(shutil.disk_usage('/'))\n",
    "    ```\n",
    "\n",
    "10. **Find a file**: You can use `shutil.which(cmd)` to locate a command. It returns the path to the command, or `None` if the command could not be found.\n",
    "\n",
    "    ```python\n",
    "    print(shutil.which('python'))\n",
    "    ```\n",
    "\n",
    "Remember to replace '/path/to/source/file', '/path/to/destination', and other paths with your actual file or directory paths.\n",
    "\n",
    "Here are some more commands from the `shutil` module:\n",
    "\n",
    "11. **Copy a directory with metadata**: You can use `shutil.copytree(src, dst, copy_function=copy2)` to copy a directory, preserving metadata.\n",
    "\n",
    "    ```python\n",
    "    shutil.copytree('/path/to/source/directory', '/path/to/destination/directory', copy_function=shutil.copy2)\n",
    "    ```\n",
    "\n",
    "12. **Copy a file with new metadata**: You can use `shutil.copy2(src, dst)` to copy a file from source to destination, preserving timestamps.\n",
    "\n",
    "    ```python\n",
    "    shutil.copy2('/path/to/source/file', '/path/to/destination/file')\n",
    "    ```\n",
    "\n",
    "13. **Create a symbolic link**: You can use `shutil.copymode(src, dst)` to copy the permission bits from `src` to `dst`. The file contents, owner, and group are unaffected.\n",
    "\n",
    "    ```python\n",
    "    shutil.copymode('/path/to/source/file', '/path/to/destination/file')\n",
    "    ```\n",
    "\n",
    "14. **Copy file permissions**: You can use `shutil.copymode(src, dst)` to copy the permission bits from `src` to `dst`.\n",
    "\n",
    "    ```python\n",
    "    shutil.copymode('/path/to/source/file', '/path/to/destination/file')\n",
    "    ```\n",
    "\n",
    "15. **Get terminal size**: You can use `shutil.get_terminal_size()` to get the size of the terminal window.\n",
    "\n",
    "    ```python\n",
    "    print(shutil.get_terminal_size())\n",
    "    ```\n",
    "\n",
    "16. **Ignore certain files or directories while copying**: You can use `shutil.copytree(src, dst, ignore=shutil.ignore_patterns('*~', 'tmp*'))` to copy a directory but ignore files/directories that match the pattern '*~' and 'tmp*'.\n",
    "\n",
    "    ```python\n",
    "    shutil.copytree('/path/to/source/directory', '/path/to/destination/directory', ignore=shutil.ignore_patterns('*~', 'tmp*'))\n",
    "    ```\n",
    "\n",
    "17. **Copy a file, preserving permissions**: You can use `shutil.copy(src, dst)` to copy a file from source to destination, preserving file permissions.\n",
    "\n",
    "    ```python\n",
    "    shutil.copy('/path/to/source/file', '/path/to/destination/file')\n",
    "    ```\n",
    "\n",
    "18. **Check if two files are identical**: You can use `filecmp.cmp(f1, f2)` to compare two files.\n",
    "\n",
    "    ```python\n",
    "    import filecmp\n",
    "    print(filecmp.cmp('/path/to/file1', '/path/to/file2'))\n",
    "    ```\n",
    "\n",
    "19. **Compare directories**: You can use `filecmp.dircmp(a, b)` to compare two directories.\n",
    "\n",
    "    ```python\n",
    "    import filecmp\n",
    "    dcmp = filecmp.dircmp('/path/to/directory1', '/path/to/directory2')\n",
    "    dcmp.report()\n",
    "    ```\n",
    "\n",
    "20. **Get environment variables**: You can use `os.environ` to get environment variables.\n",
    "\n",
    "    ```python\n",
    "    import os\n",
    "    print(os.environ['HOME'])\n",
    "    ```\n",
    "\n",
    "Remember to replace '/path/to/source/file', '/path/to/destination', and other paths with your actual file or directory paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i am damodar , eren , mikasa ,levi .Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. This course will be taught in Hindi language.\n"
     ]
    }
   ],
   "source": [
    "with open('test1.txt','r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File reading and writing eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code is opening a file and reading a portion of its contents. Here's a breakdown of what each line does:\n",
    "\n",
    "1. `with open(\"text.txt\",'rb') as f:` This line opens the file named \"text.txt\" in binary read mode ('rb'). The 'b' indicates that the file is opened in binary mode, which is used when dealing with non-text files like images or executable files. The file object is referred to as `f` within the `with` block.\n",
    "\n",
    "2. `file = io.BufferedReader(f):` This line wraps the file object `f` with a `BufferedReader` object. `BufferedReader` is a class in the `io` module that implements a buffer to provide more efficient reading of bytes.\n",
    "\n",
    "3. `data= file.read(100):` This line reads the first 100 bytes from the file (or less if the file is smaller than 100 bytes) and stores the result in the `data` variable.\n",
    "\n",
    "4. `print(data):` This line prints the data read from the file. Since the file was opened in binary mode, `data` will be a bytes object, not a string.\n",
    "\n",
    "Remember, when working with files in binary mode, the data you read from or write to the file must be bytes, not text. If you want to convert the bytes to text, you can use the `decode()` method of the bytes object, provided that you know the correct character encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name': 'Damodar',\n",
    "    'age': 25,\n",
    "    'city': 'Bangalore',\n",
    "    'email': 'damodar@gm.com',\n",
    "    'is_student': True,\n",
    "    'courses': ['Python', 'Data Science', 'Machine Learning'],\n",
    "    'phone_numbers': {\n",
    "        'home': 1234567890,\n",
    "        'work': 9876543210\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is opening a file named 'data.json' in write mode using the `open()` function. It then uses the `json.dump()` function to write the contents of the `data` variable to the file. The `with` statement is used to ensure that the file is properly closed after writing.\n",
    "with open('data.json','w') as f:\n",
    "    json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Damodar',\n",
       " 'age': 25,\n",
       " 'city': 'Bangalore',\n",
       " 'email': 'damodar@gm.com',\n",
       " 'is_student': True,\n",
       " 'courses': ['Python', 'Data Science', 'Machine Learning'],\n",
       " 'phone_numbers': {'home': 1234567890, 'work': 9876543210}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Science'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['courses'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test3.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    for i in data:\n",
    "        # `w.writerow([i, data[i]])` is writing a single row to the CSV file. The `writerow()` method takes a list as an argument, where each element in the list represents a column in the CSV file. In this case, `[i, data[i]]` is a list with two elements: `i` and `data[i]`. This will write the values of `i` and `data[i]` as separate columns in the CSV file.\n",
    "        w.writerow([i, data[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Damodar',\n",
       " 'age': 25,\n",
       " 'city': 'Bangalore',\n",
       " 'email': 'damodar@gm.com',\n",
       " 'is_student': True,\n",
       " 'courses': ['Python', 'Data Science', 'Machine Learning'],\n",
       " 'phone_numbers': {'home': 1234567890, 'work': 9876543210}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test3.csv\",'w') as f:\n",
    "    w = csv.writer(f)\n",
    "    for i in data:\n",
    "        w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json','r') as f:\n",
    "    data1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Damodar',\n",
       " 'age': 25,\n",
       " 'city': 'Bangalore',\n",
       " 'email': 'damodar@gm.com',\n",
       " 'is_student': True,\n",
       " 'courses': ['Python', 'Data Science', 'Machine Learning'],\n",
       " 'phone_numbers': {'home': 1234567890, 'work': 9876543210}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'a', 'm', 'e']\n",
      "[]\n",
      "['a', 'g', 'e']\n",
      "[]\n",
      "['c', 'i', 't', 'y']\n",
      "[]\n",
      "['e', 'm', 'a', 'i', 'l']\n",
      "[]\n",
      "['i', 's', '_', 's', 't', 'u', 'd', 'e', 'n', 't']\n",
      "[]\n",
      "['c', 'o', 'u', 'r', 's', 'e', 's']\n",
      "[]\n",
      "['p', 'h', 'o', 'n', 'e', '_', 'n', 'u', 'm', 'b', 'e', 'r', 's']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "with open('test3.csv','r') as f:\n",
    "    r = csv.reader(f)\n",
    "    for i in r:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [[\n",
    "    'name', 'age', 'city', 'email', 'is_student', 'courses', 'phone_numbers'\n",
    "], [\n",
    "    'Damodar', '25', 'Bangalore', 'damodr@g.com', 'True', \"['Python', 'Data Science', 'Machine Learning']\", \"{'home': 1234567890, 'work': 9876543210}\" \n",
    "],\n",
    " [\n",
    "     'Nikesh', '25', 'Bangalore', 'da@g.com', 'True', \"['Python', 'Data Science', 'Machine Learning']\", \"{'home': 1234567890, 'work': 9876543210}\"\n",
    " ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text4.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    for i in data2:\n",
    "        w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is opening a file named 'text4.csv' in binary write mode (`'wb'`). It then writes the bytes `b\"\\x01\\x02\\x03\"` to the file.\n",
    "with open('text4.csv','wb') as f:\n",
    "    f.write(b\"\\x01\\x02\\x03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x01\\x02\\x03'\n"
     ]
    }
   ],
   "source": [
    "with open('text4.csv','rb') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The `import io` statement is importing the `io` module in Python. The `io` module provides a set of functions and classes for working with input and output streams, such as reading and writing files.\n",
    "### Buffer read and write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, a buffer is a temporary storage area for data while it's being moved from one place to another. This concept is commonly used when performing I/O operations, such as reading from or writing to a file, sending or receiving data over a network, etc.\n",
    "\n",
    "The main advantage of using a buffer is that it allows for more efficient data processing. Instead of handling data one byte at a time, you can handle it in large blocks, which can significantly speed up your I/O operations.\n",
    "\n",
    "Python provides several classes in the `io` module for buffered I/O:\n",
    "\n",
    "1. `io.BufferedReader`: This class implements a buffer for a readable, sequential RawIO object. It provides methods like `read()`, `read1()`, `peek()`, etc.\n",
    "\n",
    "2. `io.BufferedWriter`: This class implements a buffer for a writeable, sequential RawIO object. It provides methods like `write()`, `flush()`, etc.\n",
    "\n",
    "3. `io.BufferedRandom`: This class implements a buffered I/O object combining `BufferedReader` and `BufferedWriter`. It works with a seekable RawIO object.\n",
    "\n",
    "4. `io.BufferedRWPair`: This class implements a buffered I/O object combining two RawIO objects: one readable and one writeable.\n",
    "\n",
    "Here's an example of using a buffer in Python:\n",
    "\n",
    "```python\n",
    "with open('file.txt', 'rb') as f:\n",
    "    reader = io.BufferedReader(f)\n",
    "    data = reader.read(1024)  # Read up to 1024 bytes\n",
    "```\n",
    "\n",
    "In this example, `io.BufferedReader(f)` creates a buffered reader object for the file `f`. The `read(1024)` method reads up to 1024 bytes from the file into the buffer. This allows for more efficient reading of the file compared to reading one byte at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, let's dive deeper into each of these classes:\n",
    "\n",
    "1. `io.BufferedReader`: This class is a buffered I/O implementation around a readable and sequential base Raw I/O object. It provides high-level read and seek methods that allow you to work with the file in a more efficient way. The buffer can hold a certain amount of data, and when you call `read()`, it first checks if the data is in the buffer. If it is, it returns the data from the buffer instead of directly reading from the file, which is faster.\n",
    "\n",
    "```python\n",
    "with open('file.txt', 'rb') as f:\n",
    "    reader = io.BufferedReader(f)\n",
    "    data = reader.read(1024)  # Read up to 1024 bytes\n",
    "```\n",
    "\n",
    "2. `io.BufferedWriter`: This class is a buffered I/O implementation around a writable and sequential base Raw I/O object. It provides a high-level `write()` method. When you call `write()`, it writes the data into the buffer and only writes to the file when the buffer is full, which can be more efficient than writing to the file directly each time.\n",
    "\n",
    "```python\n",
    "with open('file.txt', 'wb') as f:\n",
    "    writer = io.BufferedWriter(f)\n",
    "    writer.write(b'Hello, world!')  # Write a bytes object\n",
    "```\n",
    "\n",
    "3. `io.BufferedRandom`: This class is a buffered I/O implementation combining `BufferedReader` and `BufferedWriter`, working with a seekable Raw I/O object. It provides high-level read, write and seek methods. This is useful when you need to both read from and write to a file in a random manner.\n",
    "\n",
    "```python\n",
    "with open('file.txt', 'r+b') as f:  # Open for reading and writing\n",
    "    reader_writer = io.BufferedRandom(f)\n",
    "    data = reader_writer.read(1024)  # Read up to 1024 bytes\n",
    "    reader_writer.write(b'Hello, world!')  # Write a bytes object\n",
    "```\n",
    "\n",
    "4. `io.BufferedRWPair`: This class is a buffered I/O implementation combining two Raw I/O objects: one readable and one writeable. It doesn't implement any buffering, that needs to be implemented by the Raw I/O objects themselves. It's useful when you have two separate objects for reading and writing, but want to present them as a single bidirectional object.\n",
    "\n",
    "```python\n",
    "readable = io.BytesIO(b'Hello, world!')  # A readable bytes stream\n",
    "writeable = io.BytesIO()  # A writeable bytes stream\n",
    "reader_writer = io.BufferedRWPair(readable, writeable)\n",
    "data = reader_writer.read(5)  # Read up to 5 bytes\n",
    "reader_writer.write(b'Python')  # Write a bytes object\n",
    "```\n",
    "\n",
    "Remember, when working with files in binary mode, the data you read from or write to the file must be bytes, not text. If you want to convert the bytes to text, you can use the `decode()` method of the bytes object, provided that you know the correct character encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code snippet is opening a file named \"text.txt\" in binary write mode ('wb'). It then creates a buffered writer object using the io.BufferedWriter() function and assigns it to the variable 'file'.\n",
    "with open('text.txt','wb') as f:\n",
    "    file = io.BufferedWriter(f)\n",
    "    f.write(b\" i am damodar , eren , mikasa ,levi .Data Science Masters course is highly curated and uniquely designed according to the latest industry standards. This program instills students the skills essential to knowledge discovery efforts to identify standard, novel, and truly differentiated solutions and decision-making, including skills in managing, querying, analyzing, visualizing, and extracting meaning from extremely large data sets. This trending program provides students with the statistical, mathematical and computational skills needed to meet the large-scale data science challenges of today's professional world. You will learn all the stack required to work in data science industry including cloud infrastructure and real-time industry projects. This course will be taught in Hindi language.\")\n",
    "# The code `file.write(b\" i am damodar , eren , mikasa ,levi .Data Science Masters course\")` is writing the specified string to the file opened in binary write mode. The `b` prefix before the string indicates that it should be treated as a bytes object.\n",
    "    file.write(b\" i am damodar , eren , mikasa ,levi .Data Science Masters course\")\n",
    "    # The `file.flush()` function is used to flush the buffer and ensure that all the data written to the file is actually written to the underlying file system. It forces any buffered data to be written immediately. This is useful when you want to make sure that all the data is written to the file before performing any further operations.\n",
    "    file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' i am damodar , eren , mikasa ,levi .Data Science Masters course is highly curated and uniquely desi'\n"
     ]
    }
   ],
   "source": [
    "with open(\"text.txt\",'rb') as f:\n",
    "    file = io.BufferedReader(f)\n",
    "    data= file.read(100)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exception handling with try_except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = int (input(\"Enter your age: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is defining a custom exception class called `validateage` that inherits from the built-in `Exception` class.\n",
    "class validateage (Exception):\n",
    "    def __init__(self,msg):\n",
    "        self.msg = msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateage_age (age):\n",
    "    if age<0:\n",
    "        raise validateage (\"age should not lesser than zero\")\n",
    "    elif age > 150 :\n",
    "        raise validateage (\" Human age is too high\")\n",
    "    else :\n",
    "        print(\"age is valid\", age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    age = int (input(\"enter your age\"))\n",
    "    validateage_age(age)\n",
    "except validateage as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is my print\n"
     ]
    }
   ],
   "source": [
    "f = open('test.txt','r')\n",
    "print(\"this is my print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is some issue [Errno 2] No such file or directory: 'tet.txt'\n",
      "this is my print\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f=open('tet.txt','r')\n",
    "except Exception as e:\n",
    "    print('there is some issue',e)\n",
    "print(\"this is my print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is some issue not writable\n",
      "not writable\n",
      "this will execute no matter what\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f=open('test.txt','r')\n",
    "    f.write(\"this is my test file for exception handling\")\n",
    "except Exception as e:\n",
    "    print('there is some issue', e)\n",
    "else:\n",
    "    print('this will execute if there is no exception')\n",
    "    f.close()\n",
    "    print('file is closed')\n",
    "finally:\n",
    "    print('this will execute no matter what')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
