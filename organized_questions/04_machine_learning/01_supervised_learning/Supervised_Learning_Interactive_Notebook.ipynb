{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3baf378",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Supervised Learning - Interactive Interview Preparation\n",
    "\n",
    "This notebook contains **runnable code examples** for all major supervised learning algorithms. Practice these implementations for your interviews!\n",
    "\n",
    "## ðŸ“š Contents:\n",
    "1. [Linear Regression from Scratch](#linear-regression)\n",
    "2. [Logistic Regression from Scratch](#logistic-regression) \n",
    "3. [Decision Trees from Scratch](#decision-trees)\n",
    "4. [Model Evaluation & Metrics](#evaluation)\n",
    "5. [Real Dataset Examples](#real-examples)\n",
    "6. [Quick Interview Coding Challenges](#challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_regression, load_iris, load_boston\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(\"ðŸš€ Ready for supervised learning interview prep!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bb407",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ˆ 1. Linear Regression from Scratch\n",
    "\n",
    "**ðŸŽ¯ Interview Question**: *\"Implement linear regression from scratch using gradient descent\"*\n",
    "\n",
    "### Key Concepts to Remember:\n",
    "- **Hypothesis**: h(x) = wâ‚€ + wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™\n",
    "- **Cost Function**: J(w) = (1/2m) * Î£(h(xâ½â±â¾) - yâ½â±â¾)Â²\n",
    "- **Gradient**: âˆ‚J/âˆ‚w = (1/m) * X^T * (h(x) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionScratch:\n",
    "    \"\"\"Linear Regression implemented from scratch using gradient descent\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initialize parameters\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.n_iterations):\n",
    "            # Forward pass: compute predictions\n",
    "            y_pred = self.predict(X)\n",
    "            \n",
    "            # Compute cost (Mean Squared Error)\n",
    "            cost = (1/(2*n_samples)) * np.sum((y_pred - y)**2)\n",
    "            self.cost_history.append(cost)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "    \n",
    "    def plot_cost_history(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.cost_history, 'b-', linewidth=2)\n",
    "        plt.title('Cost Function During Training', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Iterations', fontsize=12)\n",
    "        plt.ylabel('Cost (MSE)', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "# Generate sample data for demonstration\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegressionScratch(learning_rate=0.01, n_iterations=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸŽ¯ Linear Regression Results:\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "print(f\"Learned Weight: {model.weights[0]:.4f}\")\n",
    "print(f\"Learned Bias: {model.bias:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Data and predictions\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X_test, y_test, color='blue', alpha=0.6, label='Actual')\n",
    "plt.scatter(X_test, y_pred, color='red', alpha=0.6, label='Predicted')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Predictions vs Actual')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "plt.subplot(1, 3, 2)\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Cost history\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(model.cost_history, 'b-', linewidth=2)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost (MSE)')\n",
    "plt.title('Training Cost')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280f07e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ 2. Logistic Regression from Scratch\n",
    "\n",
    "**ðŸŽ¯ Interview Question**: *\"Implement logistic regression from scratch with gradient descent\"*\n",
    "\n",
    "### Key Concepts to Remember:\n",
    "- **Sigmoid Function**: Ïƒ(z) = 1/(1 + e^(-z))\n",
    "- **Cost Function**: J(w) = -(1/m) * Î£[y*log(h(x)) + (1-y)*log(1-h(x))]\n",
    "- **Gradient**: âˆ‚J/âˆ‚w = (1/m) * X^T * (h(x) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    \"\"\"Logistic Regression implemented from scratch\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost_history = []\n",
    "    \n",
    "    def _add_intercept(self, X):\n",
    "        \"\"\"Add bias column to feature matrix\"\"\"\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Sigmoid activation function\"\"\"\n",
    "        # Clip z to prevent overflow\n",
    "        z = np.clip(z, -250, 250)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _cost_function(self, h, y):\n",
    "        \"\"\"Calculate logistic regression cost (cross-entropy)\"\"\"\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Add intercept term\n",
    "        X = self._add_intercept(X)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.n_iterations):\n",
    "            # Forward pass\n",
    "            z = np.dot(X, self.weights)\n",
    "            h = self._sigmoid(z)\n",
    "            \n",
    "            # Calculate cost\n",
    "            cost = self._cost_function(h, y)\n",
    "            self.cost_history.append(cost)\n",
    "            \n",
    "            # Calculate gradient\n",
    "            gradient = np.dot(X.T, (h - y)) / y.size\n",
    "            \n",
    "            # Update weights\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities\"\"\"\n",
    "        X = self._add_intercept(X)\n",
    "        return self._sigmoid(np.dot(X, self.weights))\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"Make binary predictions\"\"\"\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "\n",
    "# Generate sample classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, \n",
    "                          n_informative=2, random_state=42, n_clusters_per_class=1)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegressionScratch(learning_rate=0.1, n_iterations=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸŽ¯ Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Decision boundary\n",
    "plt.subplot(1, 3, 1)\n",
    "# Create a mesh for plotting decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = model.predict_proba(mesh_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, levels=50, alpha=0.6, cmap='RdYlBu')\n",
    "scatter = plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='RdYlBu', edgecolors='black')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('Decision Boundary')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# Plot 2: Confusion Matrix\n",
    "plt.subplot(1, 3, 2)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Plot 3: Cost history\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(model.cost_history, 'b-', linewidth=2)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost (Cross-entropy)')\n",
    "plt.title('Training Cost')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nðŸ“Š Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f9011",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŒ³ 3. Decision Tree from Scratch\n",
    "\n",
    "**ðŸŽ¯ Interview Question**: *\"Implement a decision tree classifier using Gini impurity\"*\n",
    "\n",
    "### Key Concepts to Remember:\n",
    "- **Gini Impurity**: Gini = 1 - Î£(páµ¢)Â²\n",
    "- **Information Gain**: IG = Gini_parent - Î£(wáµ¢ * Gini_child_i)\n",
    "- **Splitting**: Choose feature and threshold that maximizes information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee48ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class DecisionTreeScratch:\n",
    "    \"\"\"Decision Tree Classifier implemented from scratch\"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root = None\n",
    "    \n",
    "    def _gini_impurity(self, y):\n",
    "        \"\"\"Calculate Gini impurity\"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        proportions = np.bincount(y) / len(y)\n",
    "        return 1 - np.sum(proportions ** 2)\n",
    "    \n",
    "    def _information_gain(self, parent, left_child, right_child):\n",
    "        \"\"\"Calculate information gain\"\"\"\n",
    "        weight_left = len(left_child) / len(parent)\n",
    "        weight_right = len(right_child) / len(parent)\n",
    "        \n",
    "        gain = (self._gini_impurity(parent) - \n",
    "                weight_left * self._gini_impurity(left_child) - \n",
    "                weight_right * self._gini_impurity(right_child))\n",
    "        return gain\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Find the best split for the data\"\"\"\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        n_features = X.shape[1]\n",
    "        for feature_idx in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feature_idx] <= threshold\n",
    "                right_mask = ~left_mask\n",
    "                \n",
    "                if (len(y[left_mask]) < self.min_samples_leaf or \n",
    "                    len(y[right_mask]) < self.min_samples_leaf):\n",
    "                    continue\n",
    "                \n",
    "                gain = self._information_gain(y, y[left_mask], y[right_mask])\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature_idx\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold, best_gain\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        \"\"\"Recursively build the decision tree\"\"\"\n",
    "        # Stopping criteria\n",
    "        if (depth >= self.max_depth or \n",
    "            len(set(y)) == 1 or \n",
    "            len(y) < self.min_samples_split):\n",
    "            # Return leaf node with majority class\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        \n",
    "        # Find best split\n",
    "        feature_idx, threshold, gain = self._best_split(X, y)\n",
    "        \n",
    "        if gain == 0:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        \n",
    "        # Split the data\n",
    "        left_mask = X[:, feature_idx] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        # Create node\n",
    "        node = {\n",
    "            'feature': feature_idx,\n",
    "            'threshold': threshold,\n",
    "            'gain': gain,\n",
    "            'samples': len(y),\n",
    "            'left': self._build_tree(X[left_mask], y[left_mask], depth + 1),\n",
    "            'right': self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        }\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the decision tree\"\"\"\n",
    "        self.root = self._build_tree(X, y)\n",
    "    \n",
    "    def _predict_sample(self, sample, node):\n",
    "        \"\"\"Predict a single sample\"\"\"\n",
    "        if not isinstance(node, dict):\n",
    "            return node\n",
    "        \n",
    "        if sample[node['feature']] <= node['threshold']:\n",
    "            return self._predict_sample(sample, node['left'])\n",
    "        else:\n",
    "            return self._predict_sample(sample, node['right'])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions on new data\"\"\"\n",
    "        return np.array([self._predict_sample(sample, self.root) for sample in X])\n",
    "    \n",
    "    def _get_tree_depth(self, node):\n",
    "        \"\"\"Calculate tree depth\"\"\"\n",
    "        if not isinstance(node, dict):\n",
    "            return 0\n",
    "        return 1 + max(self._get_tree_depth(node['left']), \n",
    "                      self._get_tree_depth(node['right']))\n",
    "    \n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        \"\"\"Print the tree structure\"\"\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        \n",
    "        if not isinstance(node, dict):\n",
    "            print(f\"{'  ' * depth}ðŸ“‹ Predict: Class {node}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"{'  ' * depth}ðŸŒ¿ Feature {node['feature']} <= {node['threshold']:.2f} (gain: {node['gain']:.3f}, samples: {node['samples']})\")\n",
    "        print(f\"{'  ' * depth}â”œâ”€â”€ True:\")\n",
    "        self.print_tree(node['left'], depth + 1)\n",
    "        print(f\"{'  ' * depth}â””â”€â”€ False:\")\n",
    "        self.print_tree(node['right'], depth + 1)\n",
    "\n",
    "# Generate sample data\n",
    "X, y = make_classification(n_samples=300, n_features=4, n_redundant=0, \n",
    "                          n_informative=4, random_state=42, n_classes=3)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt = DecisionTreeScratch(max_depth=4, min_samples_split=5, min_samples_leaf=2)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ðŸŽ¯ Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Tree Depth: {dt._get_tree_depth(dt.root)}\")\n",
    "\n",
    "# Print tree structure\n",
    "print(\"\\nðŸŒ³ Tree Structure:\")\n",
    "dt.print_tree()\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Feature importance (based on first split)\n",
    "plt.subplot(1, 3, 1)\n",
    "feature_names = [f'Feature {i}' for i in range(X.shape[1])]\n",
    "# Simple feature importance based on root split\n",
    "importance = np.zeros(X.shape[1])\n",
    "if isinstance(dt.root, dict):\n",
    "    importance[dt.root['feature']] = dt.root['gain']\n",
    "plt.bar(feature_names, importance)\n",
    "plt.title('Feature Importance (Root Split)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Information Gain')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 2: Confusion Matrix\n",
    "plt.subplot(1, 3, 2)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Plot 3: Class distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar([f'Class {c}' for c in unique], counts, alpha=0.7)\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d075cb1",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š 4. Model Evaluation & Metrics\n",
    "\n",
    "**ðŸŽ¯ Interview Question**: *\"How do you evaluate a classification/regression model? Write code to compute all relevant metrics.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_classification_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"Calculate all classification metrics\"\"\"\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, classification_report, roc_auc_score, \n",
    "        precision_recall_curve, roc_curve\n",
    "    )\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Confusion matrix components\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    # AUC-ROC for binary classification\n",
    "    if len(np.unique(y_true)) == 2 and y_pred_proba is not None:\n",
    "        auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
    "        results['auc_roc'] = auc_roc\n",
    "    \n",
    "    return results\n",
    "\n",
    "def comprehensive_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate all regression metrics\"\"\"\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Mean Absolute Percentage Error\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2_score': r2,\n",
    "        'mape': mape\n",
    "    }\n",
    "\n",
    "def plot_classification_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"Plot comprehensive classification evaluation\"\"\"\n",
    "    from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Confusion Matrix')\n",
    "    axes[0,0].set_xlabel('Predicted')\n",
    "    axes[0,0].set_ylabel('Actual')\n",
    "    \n",
    "    # Class distribution\n",
    "    unique, counts = np.unique(y_true, return_counts=True)\n",
    "    axes[0,1].bar([f'Class {c}' for c in unique], counts, alpha=0.7)\n",
    "    axes[0,1].set_title('True Class Distribution')\n",
    "    axes[0,1].set_xlabel('Classes')\n",
    "    axes[0,1].set_ylabel('Count')\n",
    "    \n",
    "    if y_pred_proba is not None and len(np.unique(y_true)) == 2:\n",
    "        # ROC Curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_pred_proba)\n",
    "        axes[1,0].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "        axes[1,0].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        axes[1,0].set_xlabel('False Positive Rate')\n",
    "        axes[1,0].set_ylabel('True Positive Rate')\n",
    "        axes[1,0].set_title('ROC Curve')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Precision-Recall Curve\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "        axes[1,1].plot(recall, precision, linewidth=2)\n",
    "        axes[1,1].set_xlabel('Recall')\n",
    "        axes[1,1].set_ylabel('Precision')\n",
    "        axes[1,1].set_title('Precision-Recall Curve')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        # Prediction vs True labels\n",
    "        axes[1,0].scatter(y_true, y_pred, alpha=0.6)\n",
    "        axes[1,0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "        axes[1,0].set_xlabel('True Labels')\n",
    "        axes[1,0].set_ylabel('Predicted Labels')\n",
    "        axes[1,0].set_title('Predictions vs True Labels')\n",
    "        \n",
    "        # Remove empty subplot\n",
    "        fig.delaxes(axes[1,1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"Plot comprehensive regression evaluation\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Predictions vs Actual\n",
    "    axes[0,0].scatter(y_true, y_pred, alpha=0.6)\n",
    "    axes[0,0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    axes[0,0].set_xlabel('True Values')\n",
    "    axes[0,0].set_ylabel('Predicted Values')\n",
    "    axes[0,0].set_title('Predictions vs True Values')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residuals plot\n",
    "    residuals = y_true - y_pred\n",
    "    axes[0,1].scatter(y_pred, residuals, alpha=0.6)\n",
    "    axes[0,1].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0,1].set_xlabel('Predicted Values')\n",
    "    axes[0,1].set_ylabel('Residuals')\n",
    "    axes[0,1].set_title('Residual Plot')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram of residuals\n",
    "    axes[1,0].hist(residuals, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1,0].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].set_title('Distribution of Residuals')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-Q plot (approximate)\n",
    "    from scipy import stats\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[1,1])\n",
    "    axes[1,1].set_title('Q-Q Plot of Residuals')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Demo with logistic regression\n",
    "print(\"ðŸŽ¯ Classification Metrics Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate binary classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, \n",
    "                          n_informative=2, random_state=42, n_classes=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression\n",
    "log_reg = LogisticRegressionScratch(learning_rate=0.1, n_iterations=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "class_metrics = comprehensive_classification_metrics(y_test, y_pred, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {class_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {class_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {class_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {class_metrics['f1_score']:.4f}\")\n",
    "print(f\"AUC-ROC: {class_metrics['auc_roc']:.4f}\")\n",
    "\n",
    "# Plot classification metrics\n",
    "plot_classification_metrics(y_test, y_pred, y_pred_proba)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Regression Metrics Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate regression data\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=5, noise=10, random_state=42)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train linear regression\n",
    "lin_reg = LinearRegressionScratch(learning_rate=0.01, n_iterations=1000)\n",
    "lin_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "y_pred_reg = lin_reg.predict(X_test_reg)\n",
    "\n",
    "# Calculate metrics\n",
    "reg_metrics = comprehensive_regression_metrics(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(f\"MAE: {reg_metrics['mae']:.4f}\")\n",
    "print(f\"MSE: {reg_metrics['mse']:.4f}\")\n",
    "print(f\"RMSE: {reg_metrics['rmse']:.4f}\")\n",
    "print(f\"RÂ² Score: {reg_metrics['r2_score']:.4f}\")\n",
    "print(f\"MAPE: {reg_metrics['mape']:.2f}%\")\n",
    "\n",
    "# Plot regression metrics\n",
    "plot_regression_metrics(y_test_reg, y_pred_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d4318",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ 5. Quick Interview Coding Challenges\n",
    "\n",
    "Practice these common interview questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”¥ INTERVIEW CODING CHALLENGES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Challenge 1: Implement F1 Score from scratch\n",
    "def f1_score_from_scratch(y_true, y_pred):\n",
    "    \"\"\"Calculate F1 score from confusion matrix\"\"\"\n",
    "    # Calculate confusion matrix manually\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "# Test F1 score implementation\n",
    "y_true_test = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])\n",
    "y_pred_test = np.array([1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
    "\n",
    "f1_manual, prec_manual, rec_manual = f1_score_from_scratch(y_true_test, y_pred_test)\n",
    "f1_sklearn = f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f\"Challenge 1 - F1 Score Implementation:\")\n",
    "print(f\"Manual F1: {f1_manual:.4f}\")\n",
    "print(f\"sklearn F1: {f1_sklearn:.4f}\")\n",
    "print(f\"âœ… Match: {abs(f1_manual - f1_sklearn) < 1e-6}\")\n",
    "\n",
    "# Challenge 2: Implement train-test split\n",
    "def train_test_split_scratch(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"Implement train-test split from scratch\"\"\"\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_test = int(n_samples * test_size)\n",
    "    \n",
    "    # Generate random indices\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    \n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "# Test train-test split\n",
    "X_test_data = np.random.randn(100, 3)\n",
    "y_test_data = np.random.randint(0, 2, 100)\n",
    "\n",
    "X_train_manual, X_test_manual, y_train_manual, y_test_manual = train_test_split_scratch(\n",
    "    X_test_data, y_test_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nChallenge 2 - Train-Test Split:\")\n",
    "print(f\"Original data shape: {X_test_data.shape}\")\n",
    "print(f\"Training set shape: {X_train_manual.shape}\")\n",
    "print(f\"Test set shape: {X_test_manual.shape}\")\n",
    "print(f\"âœ… Split ratio: {len(X_test_manual) / len(X_test_data):.1f}\")\n",
    "\n",
    "# Challenge 3: Implement K-Fold Cross Validation\n",
    "def kfold_cross_validation(X, y, k=5, random_state=None):\n",
    "    \"\"\"Implement K-Fold cross validation from scratch\"\"\"\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    fold_size = n_samples // k\n",
    "    \n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        start_idx = i * fold_size\n",
    "        end_idx = start_idx + fold_size if i < k-1 else n_samples\n",
    "        \n",
    "        test_indices = indices[start_idx:end_idx]\n",
    "        train_indices = np.concatenate([indices[:start_idx], indices[end_idx:]])\n",
    "        \n",
    "        folds.append({\n",
    "            'train_indices': train_indices,\n",
    "            'test_indices': test_indices,\n",
    "            'X_train': X[train_indices],\n",
    "            'X_test': X[test_indices],\n",
    "            'y_train': y[train_indices],\n",
    "            'y_test': y[test_indices]\n",
    "        })\n",
    "    \n",
    "    return folds\n",
    "\n",
    "# Test K-Fold implementation\n",
    "folds = kfold_cross_validation(X_test_data, y_test_data, k=5, random_state=42)\n",
    "\n",
    "print(f\"\\nChallenge 3 - K-Fold Cross Validation:\")\n",
    "print(f\"Number of folds: {len(folds)}\")\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f\"Fold {i+1}: Train={len(fold['train_indices'])}, Test={len(fold['test_indices'])}\")\n",
    "\n",
    "# Challenge 4: Implement Standard Scaler\n",
    "class StandardScalerScratch:\n",
    "    \"\"\"Standard Scaler implemented from scratch\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / self.std_\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        return X * self.std_ + self.mean_\n",
    "\n",
    "# Test Standard Scaler\n",
    "scaler_manual = StandardScalerScratch()\n",
    "X_scaled_manual = scaler_manual.fit_transform(X_test_data)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_sklearn = StandardScaler()\n",
    "X_scaled_sklearn = scaler_sklearn.fit_transform(X_test_data)\n",
    "\n",
    "print(f\"\\nChallenge 4 - Standard Scaler:\")\n",
    "print(f\"Original mean: {np.mean(X_test_data, axis=0)[:3]}...\") \n",
    "print(f\"Manual scaled mean: {np.mean(X_scaled_manual, axis=0)[:3]}...\")\n",
    "print(f\"sklearn scaled mean: {np.mean(X_scaled_sklearn, axis=0)[:3]}...\")\n",
    "print(f\"âœ… Match: {np.allclose(X_scaled_manual, X_scaled_sklearn)}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All challenges completed! You're ready for the interview! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044fcf08",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ Quick Reference Cheat Sheet\n",
    "\n",
    "### ðŸ”¥ Must Remember Formulas:\n",
    "\n",
    "**Linear Regression:**\n",
    "- Hypothesis: `Å· = w^T * X + b`\n",
    "- Cost: `J = (1/2m) * Î£(Å· - y)Â²`\n",
    "- Gradient: `âˆ‚J/âˆ‚w = (1/m) * X^T * (Å· - y)`\n",
    "\n",
    "**Logistic Regression:**\n",
    "- Sigmoid: `Ïƒ(z) = 1/(1 + e^(-z))`\n",
    "- Cost: `J = -(1/m) * Î£[y*log(Å·) + (1-y)*log(1-Å·)]`\n",
    "- Gradient: `âˆ‚J/âˆ‚w = (1/m) * X^T * (Å· - y)`\n",
    "\n",
    "**Metrics:**\n",
    "- Precision: `TP/(TP+FP)`\n",
    "- Recall: `TP/(TP+FN)`\n",
    "- F1-Score: `2*(Precision*Recall)/(Precision+Recall)`\n",
    "- Accuracy: `(TP+TN)/(TP+TN+FP+FN)`\n",
    "\n",
    "### ðŸŽ¯ Interview Tips:\n",
    "1. **Always ask clarifying questions** about the problem\n",
    "2. **Start with a simple baseline** before complex models\n",
    "3. **Explain your thought process** while coding\n",
    "4. **Consider edge cases** (empty data, single class, etc.)\n",
    "5. **Think about scalability** and computational complexity\n",
    "6. **Validate your implementation** with known libraries\n",
    "\n",
    "### ðŸš€ Common Gotchas:\n",
    "- Don't forget to scale features for distance-based algorithms\n",
    "- Use stratified sampling for imbalanced datasets\n",
    "- Never use test data for hyperparameter tuning\n",
    "- Check for data leakage in time series problems\n",
    "- Handle missing values appropriately\n",
    "- Consider class imbalance in evaluation metrics\n",
    "\n",
    "---\n",
    "**ðŸŽ‰ You're now ready to ace your supervised learning interviews! Practice these implementations and understand the underlying concepts. Good luck! ðŸ€**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
