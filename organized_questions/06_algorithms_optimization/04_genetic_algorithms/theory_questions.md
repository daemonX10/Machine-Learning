# Genetic Algorithms Interview Questions - Theory Questions

## Question 1

**What is a genetic algorithm (GA) and how is it inspired by biological evolution?**

**Answer:**

**Definition:**

A **Genetic Algorithm** is a metaheuristic optimization technique inspired by natural selection, where candidate solutions evolve over generations through selection, crossover, and mutation.

**Biological Inspiration:**

| Biology | GA Equivalent |
|---------|---------------|
| Individual organism | Candidate solution |
| Chromosome | Encoded solution |
| Gene | Single parameter/variable |
| Fitness (survival) | Objective function value |
| Natural selection | Selection operator |
| Reproduction | Crossover operator |
| Mutation | Mutation operator |
| Population | Set of solutions |
| Generation | One iteration |

**Core Principle:**
"Survival of the fittest" → better solutions are more likely to reproduce and pass on their traits.

**Basic GA Cycle:**
```
1. Initialize random population
2. Evaluate fitness of each individual
3. Select parents (favor high fitness)
4. Crossover: Combine parent genes
5. Mutation: Random small changes
6. Replace population with offspring
7. Repeat until termination
```

**When to Use:**
- Complex optimization with many local optima
- No gradient information available
- Large, discrete search spaces
- When "good enough" solution is acceptable

---

## Question 2

**Can you explain the terms ‘chromosome,’ ‘gene,’ and ‘allele’ in the context of GAs?**

**Answer:**

**Terminology Mapping:**

| Term | Biology | GA Definition |
|------|---------|---------------|
| **Chromosome** | DNA strand | Complete encoded solution |
| **Gene** | Single trait location | One variable/parameter position |
| **Allele** | Value at a gene | Specific value at that position |

**Example - Optimizing [x, y, z]:**

```
Chromosome: [3.5, 2.1, 8.0]  ← Complete solution
             ↑    ↑    ↑
           Gene1 Gene2 Gene3

Allele for Gene1: 3.5
Allele for Gene2: 2.1
Allele for Gene3: 8.0
```

**Encoding Types:**

| Encoding | Allele Values | Example Use |
|----------|---------------|-------------|
| Binary | 0 or 1 | Feature selection |
| Integer | 0, 1, 2, ... | Discrete choices |
| Real-valued | Any float | Continuous optimization |
| Permutation | Ordered sequence | TSP, scheduling |

**Binary Encoding Example:**
```
Chromosome: [1, 0, 1, 1, 0, 1, 0, 0]
Each bit is a gene with allele 0 or 1
Represents integer 180 in binary
```

**Key Insight:**
Chromosome encoding choice affects which crossover/mutation operators work effectively.

---

## Question 3

**Describe the process of 'selection' in genetic algorithms.**

**Answer:**

**Definition:**

Selection chooses which individuals become parents for the next generation, favoring higher-fitness solutions while maintaining some diversity.

**Common Selection Methods:**

| Method | Description | Pros/Cons |
|--------|-------------|-----------|
| **Roulette Wheel** | Probability ∝ fitness | Simple; fitness scaling issues |
| **Tournament** | Pick best of k random | Fast; controllable pressure |
| **Rank-based** | Probability ∝ rank | Avoids fitness scaling issues |
| **Truncation** | Keep top X% | Simple; may lose diversity |

**Roulette Wheel Selection:**
```
Fitness: [10, 30, 20, 40]
Probability: [10%, 30%, 20%, 40%]
Spin wheel → higher fitness more likely selected
```

**Tournament Selection:**
```
1. Randomly pick k individuals (e.g., k=3)
2. Select the one with best fitness
3. Repeat for each parent needed
```

**Selection Pressure:**
- **High pressure**: Only best reproduce → fast convergence, risk of local optima
- **Low pressure**: Random-like selection → slow convergence, better exploration

**Balancing Exploration vs Exploitation:**
- Early: Low pressure (explore)
- Late: High pressure (exploit)

**Interview Tip:**
Tournament selection is most commonly used in practice - easy to implement, tunable via tournament size.

---

## Question 4

**Explain 'crossover' and 'mutation' operations in genetic algorithms.**

**Answer:**

**Crossover (Recombination):**

Combines genetic material from two parents to create offspring.

**Types of Crossover:**

| Type | How It Works |
|------|--------------|
| **Single-point** | Cut at one point, swap tails |
| **Two-point** | Cut at two points, swap middle |
| **Uniform** | Each gene randomly from parent1 or parent2 |
| **Arithmetic** | Weighted average of parent values |

**Single-Point Crossover Example:**
```
Parent 1: [A B C | D E F]
Parent 2: [1 2 3 | 4 5 6]
                ↓
Child 1:  [A B C | 4 5 6]
Child 2:  [1 2 3 | D E F]
```

**Mutation:**

Small random changes to maintain diversity and explore new regions.

**Types of Mutation:**

| Encoding | Mutation Type |
|----------|---------------|
| Binary | Bit flip (0↔1) |
| Real-valued | Add Gaussian noise |
| Permutation | Swap two positions |
| Integer | Random resample |

**Mutation Example:**
```
Before: [1, 0, 1, 1, 0]
After:  [1, 0, 0, 1, 0]  (bit 3 flipped)
```

**Key Parameters:**
- **Crossover rate**: 0.7-0.9 (most pairs crossover)
- **Mutation rate**: 0.01-0.1 (small probability per gene)

**Balance:**
- Crossover: Exploits existing good solutions
- Mutation: Explores new areas, prevents stagnation

---

## Question 5

**What is a 'fitness function' in the context of a genetic algorithm?**

**Answer:**

**Definition:**

The **fitness function** evaluates how good a solution is - it maps each chromosome to a numerical score that the GA tries to maximize (or minimize).

**Role:**
```
Chromosome → Fitness Function → Score
[params]   →    f(params)     → 42.5
```

**Key Properties:**

| Property | Description |
|----------|-------------|
| **Objective** | Measures solution quality |
| **Discriminating** | Differentiates good from bad |
| **Fast** | Evaluated many times |
| **Bounded** | Has reasonable range |

**Examples:**

| Problem | Fitness Function |
|---------|------------------|
| Maximize equation | f(x) = equation value |
| Minimize error | f(x) = -MSE or 1/MSE |
| TSP (shortest route) | f(x) = -total_distance |
| Neural network | f(x) = validation_accuracy |
| Feature selection | f(x) = accuracy - λ × num_features |

**Design Considerations:**

1. **Normalization**: Scale fitness to comparable range
2. **Handling constraints**: Penalize invalid solutions
3. **Multi-objective**: Combine multiple criteria
4. **Noise**: Use average over multiple evaluations if stochastic

**Fitness Landscape:**
The fitness function creates a "landscape" where GA searches for peaks (maxima) or valleys (minima).

**Interview Tip:**
Designing a good fitness function is often the hardest part - it must capture what you truly want to optimize.

---

## Question 6

**How does a GA differ from other optimization techniques?**

**Answer:**

**Comparison with Other Methods:**

| Aspect | Genetic Algorithm | Gradient Descent | Random Search |
|--------|------------------|------------------|---------------|
| **Derivative needed** | No | Yes | No |
| **Population-based** | Yes | No | No |
| **Parallelizable** | Highly | Limited | Highly |
| **Local optima** | Can escape | Gets stuck | Random |
| **Convergence** | Slow | Fast (convex) | Very slow |

**GA vs Gradient Descent:**

| GA | Gradient Descent |
|----|------------------|
| Works on any function | Needs differentiable function |
| Explores globally | Follows local gradient |
| Discrete/continuous | Continuous only |
| Computationally expensive | Efficient |

**GA vs Simulated Annealing:**

| GA | Simulated Annealing |
|----|---------------------|
| Population of solutions | Single solution |
| Crossover combines solutions | Only perturbation |
| Implicit parallelism | Sequential |

**GA vs Bayesian Optimization:**

| GA | Bayesian Optimization |
|----|-----------------------|
| Many evaluations | Few evaluations |
| No model of function | Builds surrogate model |
| Simple to implement | More complex |

**When to Use GA:**
- Non-differentiable functions
- Discrete/combinatorial problems
- Multi-modal landscapes (many local optima)
- Can afford many function evaluations
- Want diverse set of solutions

---

## Question 7

**What are the typical stopping conditions for a GA?**

**Answer:**

**Common Stopping Criteria:**

| Criterion | Description |
|-----------|-------------|
| **Max generations** | Stop after N iterations |
| **Max evaluations** | Stop after N fitness calls |
| **Fitness threshold** | Stop when fitness > target |
| **Stagnation** | Stop if no improvement for K generations |
| **Time limit** | Stop after T seconds |
| **Convergence** | Stop when population diversity is low |

**Implementation Examples:**

```python
# Max generations
if generation >= 1000:
    stop = True

# Fitness threshold
if best_fitness >= 0.99:
    stop = True

# Stagnation detection
if generations_without_improvement > 50:
    stop = True

# Convergence (population too similar)
if population_std < 0.001:
    stop = True
```

**Practical Approach - Combine Multiple:**
```python
def should_stop():
    return (generation >= max_gen or
            best_fitness >= target or
            stagnation_count > patience or
            time.time() - start > max_time)
```

**Trade-offs:**

| Too Early | Too Late |
|-----------|----------|
| Suboptimal solution | Wasted computation |
| Fast | Slow |
| May miss global optimum | Diminishing returns |

**Interview Tip:**
Use stagnation detection - if best fitness hasn't improved for many generations, further iterations are unlikely to help.

---

## Question 8

**What is ‘elitism’ in GAs and why might it be used?**

**Answer:**

**Definition:**

**Elitism** ensures the best individual(s) from the current generation are copied unchanged to the next generation, preventing loss of good solutions.

**Without Elitism:**
```
Generation N: Best = 95 fitness
Crossover/Mutation →
Generation N+1: Best = 92 fitness  ← Lost best solution!
```

**With Elitism:**
```
Generation N: Best = 95 fitness
Copy top 2 individuals →
Generation N+1: Guaranteed to have 95 fitness individual
```

**Implementation:**
```python
# Sort population by fitness
population.sort(key=fitness, reverse=True)

# Copy top k (elite) to next generation
next_gen = population[:elite_count]

# Fill rest with crossover/mutation
while len(next_gen) < pop_size:
    parents = select(population)
    child = crossover_and_mutate(parents)
    next_gen.append(child)
```

**Benefits:**

| Benefit | Description |
|---------|-------------|
| **Monotonic improvement** | Best fitness never decreases |
| **Faster convergence** | Good solutions preserved |
| **Stability** | Reduces randomness in progress |

**Caution:**
- Too much elitism → premature convergence
- Population becomes copies of elite
- Typically elite_count = 1-5% of population

**Common Practice:**
Keep 1-2 elite individuals per generation.

---

## Question 9

**Explain the concept of ‘genetic drift’ in GAs.**

**Answer:**

**Definition:**

**Genetic drift** is the random loss of genetic diversity in a population, where certain alleles disappear by chance rather than selection pressure.

**How It Happens in GAs:**
```
Generation 1: Allele A present in 30% of population
Random selection/sampling →
Generation 50: Allele A in 0% (lost) or 100% (fixed)
```

**Causes:**
- Small population size
- Random sampling in selection
- Stochastic crossover/mutation

**Problems:**

| Effect | Impact |
|--------|--------|
| Loss of diversity | Population becomes homogeneous |
| Premature convergence | Stuck in suboptimal region |
| Reduced exploration | Can't find better solutions |

**Genetic Drift vs Selection:**

| Genetic Drift | Selection |
|---------------|-----------|
| Random changes | Fitness-based changes |
| Happens by chance | Happens by design |
| More in small populations | Independent of pop size |

**Mitigation Strategies:**

1. **Larger populations**: Reduce random effects
2. **Immigration**: Inject new random individuals
3. **Mutation**: Reintroduce lost alleles
4. **Niching/crowding**: Maintain diversity explicitly
5. **Island models**: Multiple subpopulations exchange

**Interview Tip:**
Genetic drift is why small populations converge prematurely - always balance population size with computational cost.

---

## Question 10

**What is a 'multi-objective genetic algorithm'?**

**Answer:**

**Definition:**

A **Multi-Objective GA (MOGA)** optimizes multiple conflicting objectives simultaneously, finding a set of trade-off solutions (Pareto front) rather than a single optimal.

**Example - Car Design:**
- Objective 1: Minimize cost
- Objective 2: Maximize safety
- Objective 3: Maximize fuel efficiency

These conflict: safer cars cost more.

**Pareto Optimality:**

A solution is **Pareto optimal** if no objective can be improved without worsening another.

```
Pareto Front:
Cost ↑
  |  ●
  |   ●
  |    ●●
  |      ●●
  └──────────→ Safety
```

**Popular Algorithms:**

| Algorithm | Key Feature |
|-----------|-------------|
| **NSGA-II** | Fast non-dominated sorting |
| **SPEA2** | Strength Pareto approach |
| **MOEA/D** | Decomposes into subproblems |

**NSGA-II Key Concepts:**
1. **Non-dominated sorting**: Rank solutions into fronts
2. **Crowding distance**: Prefer spread-out solutions
3. **Binary tournament**: Select using rank, then crowding

**Output:**
Not one solution, but a set of Pareto-optimal solutions. Decision-maker chooses based on preferences.

**Use Cases:**
- Engineering design (cost vs performance)
- Portfolio optimization (risk vs return)
- ML (accuracy vs fairness vs speed)

---

## Question 11

**Can you describe what ‘gene expression programming’ is?**

**Answer:**

**Definition:**

**Gene Expression Programming (GEP)** is a GA variant that evolves computer programs/expressions, where linear chromosomes encode tree-structured expressions.

**Key Innovation:**

Separates genotype (linear chromosome) from phenotype (expression tree).

```
Genotype (linear): [+, *, a, b, -, c, d]
         ↓ Express
Phenotype (tree):    +
                   /   \
                  *     -
                 / \   / \
                a   b c   d

Expression: (a*b) + (c-d)
```

**GEP vs Genetic Programming (GP):**

| GEP | GP |
|-----|-----|
| Linear chromosomes | Tree chromosomes |
| Easy genetic operators | Complex tree operators |
| Expression trees decoded | Trees evolved directly |
| More efficient | More intuitive |

**Chromosome Structure:**
- **Head**: Can contain functions or terminals
- **Tail**: Only terminals (ensures valid trees)

**Applications:**
- Symbolic regression (discover formulas)
- Classification rules
- Time series prediction
- Automatic programming

**Advantages:**
- Simple crossover/mutation on linear string
- Always produces valid expressions
- Compact representation

**Interview Tip:**
GEP is used when you want to evolve mathematical expressions or programs, not just parameters.

---

## Question 12

**What are ‘memetic algorithms’ and how do they differ from traditional GAs?**

**Answer:**

**Definition:**

**Memetic Algorithms (MA)** combine evolutionary algorithms with local search - after genetic operations, each individual is improved through local optimization.

**The Concept:**

```
Standard GA:     Selection → Crossover → Mutation → Next Gen
Memetic:         Selection → Crossover → Mutation → LOCAL SEARCH → Next Gen
```

**Why "Memetic":**
Named after "memes" (cultural units) - solutions are refined through learning (local search), not just inherited (genetics).

**How Local Search Helps:**

| GA Alone | GA + Local Search |
|----------|-------------------|
| Explores broadly | Explores + exploits locally |
| Solutions "near" optimum | Solutions "at" local optimum |
| Slower convergence | Faster fine-tuning |

**Common Local Search Methods:**
- Gradient descent
- Hill climbing
- Simulated annealing (light)
- Pattern search

**Trade-offs:**

| Advantage | Disadvantage |
|-----------|--------------|
| Better solutions | More computation per generation |
| Faster convergence | May converge prematurely |
| Combines global + local | More complex to implement |

**When to Use:**
- Fitness evaluation is not the bottleneck
- Solutions need fine-tuning
- Problem has smooth local structure

**Interview Tip:**
Memetic algorithms are hybrid - "nature + nurture" - combining evolutionary exploration with local exploitation.

---

## Question 13

**How does 'parallelization' improve the performance of genetic algorithms?**

**Answer:**

**Why GAs are Naturally Parallel:**

- Fitness evaluations are independent
- Each individual can be evaluated simultaneously
- Population-based → embarrassingly parallel

**Parallelization Approaches:**

| Approach | Description |
|----------|-------------|
| **Master-slave** | One process coordinates, workers evaluate fitness |
| **Island model** | Multiple subpopulations evolve independently |
| **Cellular GA** | Grid of individuals, local neighborhoods |
| **GPU parallelization** | Thousands of concurrent evaluations |

**Master-Slave:**
```
Master: Manages population, selection, crossover
Slaves: Evaluate fitness in parallel
Speedup ≈ N workers (if fitness is expensive)
```

**Island Model:**
```
Island 1 ←→ Island 2 ←→ Island 3
Each evolves independently
Periodic migration of best individuals
```

**Performance Gains:**

| Bottleneck | Speedup |
|------------|---------|
| Fitness evaluation | Near-linear with processors |
| Genetic operators | Modest gains |
| Communication | Overhead to consider |

**Best Practices:**
- Parallelize fitness evaluation first (biggest gain)
- Use island model for diversity + parallelism
- Balance computation vs communication cost

**Tools:** DEAP, PyGAD support multiprocessing

---

## Question 14

**What is a 'steady-state genetic algorithm'?**

**Answer:**

**Definition:**

A **steady-state GA** replaces only 1-2 individuals per generation (rather than the entire population), maintaining continuity.

**Generational vs Steady-State:**

| Generational GA | Steady-State GA |
|-----------------|-----------------|
| Replace entire population | Replace 1-2 individuals |
| Clear generations | Continuous evolution |
| Larger changes per step | Gradual changes |

**Steady-State Algorithm:**
```
1. Select 2 parents
2. Create 1-2 offspring via crossover/mutation
3. Evaluate offspring fitness
4. Replace worst individual(s) in population
5. Repeat (no distinct generations)
```

**Advantages:**

| Benefit | Description |
|---------|-------------|
| Faster good solution use | New good solutions immediately available |
| Better elitism | Best solutions naturally persist |
| Less disruptive | Population changes gradually |

**Disadvantages:**
- Less diversity (population changes slowly)
- May converge prematurely
- Harder to parallelize

**Replacement Strategies:**
- Replace worst individual
- Replace random individual
- Replace similar individual (crowding)

**When to Use:**
- When fitness evaluation is expensive (reuse good solutions)
- When gradual convergence is preferred
- Online/streaming optimization

---

## Question 15

**Describe 'island model GAs' and their benefits.**

**Answer:**

**Definition:**

**Island Model GA** runs multiple separate subpopulations ("islands") that evolve independently, with occasional migration of individuals between islands.

**Structure:**
```
Island 1 ←──→ Island 2
   ↕              ↕
Island 4 ←──→ Island 3

Each island: independent GA
Migration: periodic exchange of best individuals
```

**Key Parameters:**
- Number of islands
- Island population size
- Migration interval (every N generations)
- Migration rate (how many individuals)
- Topology (ring, full, random connections)

**Benefits:**

| Benefit | Explanation |
|---------|-------------|
| **Diversity preservation** | Islands explore different regions |
| **Parallel efficiency** | Islands evolve independently |
| **Escape local optima** | Migration introduces new genes |
| **Scalability** | Easy to add more islands |

**Migration Policies:**
- **Ring**: Each island sends to neighbor
- **Random**: Send to random island
- **Best-to-random**: Best individuals migrate

**How It Prevents Premature Convergence:**
- Each island may converge to different local optima
- Migration mixes solutions
- Best from each region combine

**Practical Use:**
- Distributed computing (one island per machine)
- GPU clusters
- Cloud computing

---

## Question 16

**What is the role of ‘crowding’ and ‘niche’ in GAs?**

**Answer:**

**Definition:**

**Niching** techniques maintain population diversity by creating stable subpopulations around multiple optima. **Crowding** is one method to achieve this.

**Why Needed:**
Standard GAs converge to one solution. For multi-modal problems (multiple optima), we want to find ALL optima.

**Crowding:**
Replace individuals with similar ones, not random.

```
New offspring created →
Find most similar individual in population →
Replace that individual

Result: Similar solutions compete, diverse solutions coexist
```

**Niching Methods:**

| Method | How It Works |
|--------|--------------|
| **Crowding** | Replace similar individuals |
| **Fitness sharing** | Reduce fitness in crowded regions |
| **Clearing** | Only best in niche survives |
| **Speciation** | Group similar, mate within groups |

**Fitness Sharing:**
$$f'(x) = \frac{f(x)}{1 + \sum_{j} sh(d_{ij})}$$

Where $sh(d)$ penalizes nearby individuals.

**When to Use:**
- Multi-modal optimization (multiple good solutions)
- Diversity is important
- Want to map entire fitness landscape
- Ensemble generation

**Example:**
Finding multiple peaks of a function - niching keeps solutions at each peak instead of all converging to one.

---

## Question 17

**What is ‘gene duplication’ and ‘gene deletion’ in the context of GAs?**

**Answer:**

**Definition:**

**Gene duplication** and **deletion** are operators that change chromosome length, allowing variable-length solutions to evolve.

**Standard GA:** Fixed chromosome length
**Variable-length GA:** Chromosome can grow or shrink

**Gene Duplication:**
```
Before: [A, B, C, D]
After:  [A, B, B, C, D]  ← B duplicated
```

**Gene Deletion:**
```
Before: [A, B, C, D]
After:  [A, C, D]  ← B deleted
```

**When Useful:**

| Application | Why Variable Length |
|-------------|---------------------|
| Neural network architecture | Optimal size unknown |
| Feature selection | Unknown number of features |
| Rule systems | Variable number of rules |
| Program evolution | Code length varies |

**Biological Inspiration:**
- In nature, gene duplication is key to evolution
- Duplicated genes can mutate independently
- Creates genetic "raw material" for new functions

**Challenges:**
- Crossover between different-length chromosomes
- Bloat (uncontrolled growth)
- Introns (non-functional segments)

**Controlling Bloat:**
- Length penalty in fitness function
- Maximum length limit
- Parsimony pressure (prefer shorter solutions)

**Interview Tip:**
Variable-length GAs are useful for structure optimization where the optimal size is unknown.

---

## Question 18

**Describe an application of GAs in machine learning model optimization.**

**Answer:**

**Application: Hyperparameter Optimization**

**Scenario:** Tune hyperparameters for a neural network.

**Chromosome Encoding:**
```
[learning_rate, batch_size, num_layers, neurons_per_layer, dropout, optimizer]
[0.001,         32,         3,          128,               0.3,     'adam']
```

**Fitness Function:**
```python
def fitness(chromosome):
    model = build_model(chromosome)
    model.fit(X_train, y_train)
    return model.evaluate(X_val, y_val)  # Validation accuracy
```

**GA vs Grid/Random Search:**

| Method | Evaluations Needed | Quality |
|--------|-------------------|---------|
| Grid Search | Exponential | Exhaustive |
| Random Search | Many | Hit or miss |
| GA | Fewer | Guided search |

**Process:**
1. Initialize random hyperparameter combinations
2. Train each model, evaluate validation accuracy
3. Select best performers
4. Crossover: mix hyperparameters from good models
5. Mutation: random tweaks
6. Repeat until convergence

**Other ML Applications:**
- Feature selection (binary chromosome)
- Neural architecture search (NAS)
- Ensemble selection
- Preprocessing pipeline optimization

**Advantage:**
GA can handle mixed types (categorical + continuous) and complex interactions between hyperparameters.

---

## Question 19

**What are the challenges of using GAs in real-time applications?**

**Answer:**

**Key Challenges:**

| Challenge | Description |
|-----------|-------------|
| **Computational time** | Many fitness evaluations needed |
| **Latency** | Cannot wait for many generations |
| **Convergence speed** | May not find good solution in time |
| **Resource usage** | CPU/memory intensive |

**Real-Time Constraints:**
```
Deadline: 100ms response time
GA needs: 1000 generations × 50ms/evaluation = Too slow!
```

**Mitigation Strategies:**

| Strategy | How It Helps |
|----------|--------------|
| **Smaller population** | Fewer evaluations per generation |
| **Warm starting** | Initialize from previous solution |
| **Anytime algorithm** | Return best-so-far if interrupted |
| **Parallel evaluation** | GPU/multicore speedup |
| **Surrogate models** | Cheap fitness approximation |

**Warm Starting for Real-Time:**
```
Time T: Find solution S
Time T+1: Initialize population near S
→ Fewer generations needed
```

**Surrogate-Assisted GA:**
- Train fast model to approximate expensive fitness
- Evaluate most individuals with surrogate
- Use real fitness only for promising individuals

**When GAs Can Work Real-Time:**
- Fitness evaluation is fast (milliseconds)
- Problem changes slowly (can reuse solutions)
- Approximate solutions acceptable
- Parallel hardware available

---

## Question 20

**Describe how GAs can be used to optimize portfolio allocations in finance.**

**Answer:**

**Problem:** Allocate capital across N assets to maximize return and minimize risk.

**Chromosome Encoding:**
```
[w1, w2, w3, ..., wN]  where wi = weight of asset i
Constraint: sum(wi) = 1, wi >= 0
```

**Example:**
```
[0.3, 0.2, 0.15, 0.35]  → 30% Stock A, 20% Stock B, ...
```

**Fitness Function (Multi-objective):**

$$\text{Fitness} = \frac{\text{Expected Return}}{\text{Risk (Volatility)}} - \lambda \cdot \text{Constraint Violation}$$

Or use NSGA-II for Pareto front of return vs risk.

**Handling Constraints:**
- Normalize weights to sum to 1
- Penalty for negative weights
- Repair operators

**Crossover for Weights:**
```
Parent 1: [0.3, 0.2, 0.5]
Parent 2: [0.1, 0.6, 0.3]
Child:    [0.2, 0.4, 0.4]  (blend, then normalize)
```

**Advantages of GA:**

| Advantage | Description |
|-----------|-------------|
| Handles constraints | Non-linear constraints OK |
| Multi-objective | Find return-risk trade-offs |
| Non-convex | Works with complex models |
| Discrete assets | Binary include/exclude |

**Extensions:**
- Transaction costs in fitness
- Cardinality constraints (max N assets)
- Sector diversification rules

**Output:** Set of Pareto-optimal portfolios for investor to choose from.

---

## Question 21

**What are the common genetic representation schemes used for different problem types?**

**Answer:**

**Representation Schemes:**

| Problem Type | Encoding | Example |
|--------------|----------|---------|
| **Continuous optimization** | Real-valued | [3.14, 2.71, 1.41] |
| **Combinatorial (subset)** | Binary | [1, 0, 1, 1, 0] |
| **Ordering (TSP)** | Permutation | [3, 1, 4, 2, 5] |
| **Tree/expression** | Tree-based | GP trees |
| **Categorical choices** | Integer | [2, 0, 3, 1] |

**Binary Encoding:**
```
Feature selection: [1,0,1,0,0,1] → Use features 0, 2, 5
Knapsack: [1,0,1,1] → Take items 0, 2, 3
```

**Real-Valued Encoding:**
```
Neural network weights: [0.5, -0.3, 1.2, ...]
Function optimization: f(x1, x2) → [x1, x2]
```

**Permutation Encoding:**
```
TSP: [3, 1, 4, 2] → Visit city 3, then 1, then 4, then 2
Scheduling: [2, 0, 1] → Job order
```

**Choosing Representation:**

| Consideration | Guidance |
|---------------|----------|
| Natural mapping | Encode problem naturally |
| Valid solutions | Operators produce valid offspring |
| Completeness | All solutions representable |
| Non-redundancy | One encoding per solution |

**Important:** Representation determines which crossover/mutation operators work correctly!

---

## Question 22

**What are some methods to ensure genetic diversity in a GA population?**

**Answer:**

**Why Diversity Matters:**
- Prevents premature convergence
- Maintains exploration capability
- Avoids local optima traps

**Diversity Maintenance Methods:**

| Method | Description |
|--------|-------------|
| **High mutation rate** | More random changes |
| **Large population** | More genetic material |
| **Niching/crowding** | Protect diverse niches |
| **Fitness sharing** | Penalize similar solutions |
| **Immigration** | Inject random individuals |
| **Island model** | Separate subpopulations |
| **Restrict mating** | Only dissimilar can mate |

**Practical Implementations:**

**1. Random Immigrants:**
```python
# Replace worst 10% with random individuals each generation
n_immigrants = int(0.1 * pop_size)
population[-n_immigrants:] = [random_individual() for _ in range(n_immigrants)]
```

**2. Fitness Sharing:**
```python
# Reduce fitness if neighbors are similar
shared_fitness = fitness / (1 + count_similar_neighbors)
```

**3. Diversity Metric Monitoring:**
```python
# Track population diversity
diversity = average_pairwise_distance(population)
if diversity < threshold:
    increase_mutation_rate()
```

**4. Age-Based Replacement:**
- Track individual age
- Replace old individuals even if fit
- Prevents stagnation

**Interview Tip:**
Adaptive approaches - increase mutation or add immigrants when diversity drops - work well in practice.

---

## Question 23

**Can you explain how to deal with constraints in genetic algorithms?**

**Answer:**

**Types of Constraints:**
- Equality: $g(x) = 0$
- Inequality: $h(x) \leq 0$
- Box: $a \leq x \leq b$

**Constraint Handling Methods:**

| Method | Description |
|--------|-------------|
| **Penalty function** | Subtract penalty from fitness |
| **Repair operators** | Fix invalid solutions |
| **Decoder** | Genotype always maps to valid phenotype |
| **Feasibility rules** | Feasible beats infeasible |
| **Separate constraints** | Multi-objective with constraints |

**1. Penalty Function:**
```python
def fitness_with_penalty(x):
    base_fitness = objective(x)
    violation = constraint_violation(x)
    return base_fitness - penalty_coefficient * violation
```

**2. Repair Operator:**
```python
def repair(x):
    # Example: Ensure weights sum to 1
    x = np.abs(x)  # Make positive
    x = x / np.sum(x)  # Normalize
    return x
```

**3. Death Penalty:**
```python
if not is_feasible(x):
    fitness = -infinity  # Never selected
```

**4. Feasibility Rules (Deb's):**
- Feasible always beats infeasible
- Between feasible: compare objective
- Between infeasible: compare constraint violation

**Best Practices:**
- Start with repair if simple to implement
- Use penalty for complex constraints
- Dynamic penalty: increase as generations progress
- Seed population with some feasible solutions

---

## Question 24

**Describe how a GA might become trapped in a local optimum and how to avoid it.**

**Answer:**

**How Trapping Happens:**

```
Fitness Landscape:
      ●← GA converges here (local optimum)
     /|\ 
    / | \        ●← Global optimum
   /  |  \      /|\
  /   |   \    / | \
```

**Causes:**
- Selection pressure too high (only best survive)
- Low mutation rate (no exploration)
- Population converges (loses diversity)
- Similar genes dominate (genetic drift)

**Symptoms:**
- Fitness plateau for many generations
- Population becomes homogeneous
- All individuals nearly identical

**Prevention Strategies:**

| Strategy | How It Helps |
|----------|--------------|
| Higher mutation rate | Escape local region |
| Island model | Different islands explore differently |
| Fitness sharing | Maintain diverse niches |
| Restart | Reinitialize if stuck |
| Adaptive operators | Increase mutation when stuck |

**Escape Techniques:**

**1. Random Restart:**
```python
if stagnation_count > patience:
    keep_best_n = 5
    population = [random_individual() for _ in range(pop_size - keep_best_n)]
    population.extend(elite[:keep_best_n])
```

**2. Hypermutation:**
```python
if no_improvement(generations=50):
    mutation_rate *= 10  # Temporary increase
```

**3. Simulated Annealing Hybrid:**
Accept some worse solutions probabilistically.

**Interview Tip:**
Premature convergence is GA's main failure mode - always monitor diversity and have escape mechanisms.

---

## Question 25

**Describe strategies for parallelizing genetic algorithms and the trade-offs involved.**

**Answer:**

**Parallelization Strategies:**

**1. Global Parallelization (Master-Slave):**
```
Master: Selection, crossover, mutation
Workers: Parallel fitness evaluation
```
- Best for expensive fitness functions
- Speedup ≈ number of workers
- Communication overhead for coordination

**2. Island Model:**
```
Island 1   Island 2   Island 3
   GA1        GA2        GA3
     \         |         /
      \____Migration____/
```
- Independent evolution + periodic exchange
- Excellent scalability
- Diversity naturally maintained

**3. Cellular/Diffusion Model:**
```
Grid of individuals
Each mates only with neighbors
Gradual spread of good genes
```

**Trade-offs:**

| Strategy | Pros | Cons |
|----------|------|------|
| Master-slave | Simple, any fitness | Sync bottleneck |
| Island | Scalable, diverse | Migration tuning |
| Cellular | Fine-grained | Complex to implement |

**Implementation Considerations:**

| Factor | Trade-off |
|--------|-----------|
| Synchronous vs async | Determinism vs speed |
| Migration rate | Diversity vs convergence |
| Communication | Frequency vs overhead |

**Tools:**
- Python: `multiprocessing`, DEAP with `scoop`
- Distributed: Spark, Dask
- GPU: cuGA, custom CUDA

**Best Practice:** Start with master-slave for fitness parallelization, add islands if diversity is an issue.

---

## Question 26

**Describe how you would apply a GA to an image recognition problem with many features.**

**Answer:**

**Application: Feature Selection for Image Classification**

**Problem:** 
- 10,000 image features (pixel intensities, HOG, SIFT, etc.)
- Only subset is relevant for classification
- Want to find optimal feature subset

**Chromosome Encoding:**
```
Binary: [1, 0, 0, 1, 1, 0, ...] (length = 10,000)
1 = use feature, 0 = exclude
```

**Fitness Function:**
```python
def fitness(chromosome):
    # Select features
    selected = [i for i, bit in enumerate(chromosome) if bit == 1]
    X_subset = X[:, selected]
    
    # Train classifier (fast one)
    clf = RandomForestClassifier(n_estimators=50)
    
    # Cross-validation accuracy
    score = cross_val_score(clf, X_subset, y, cv=3).mean()
    
    # Penalty for too many features
    penalty = 0.001 * len(selected)
    
    return score - penalty
```

**Practical Considerations:**

| Challenge | Solution |
|-----------|----------|
| Large chromosome | Initialize with few 1s (sparse) |
| Slow fitness | Use fast classifier, small CV |
| Local optima | Island model, high mutation |

**Alternative: Real-valued for weights:**
```
[0.8, 0.1, 0.0, 0.9, ...]
Threshold to select features
```

**Advantages of GA:**
- Handles feature interactions
- No gradient needed
- Can incorporate prior knowledge in initialization
- Naturally handles large search space

---

## Question 27

**Explain how you might use a GA to optimize the parameters of an algorithm trading model.**

**Answer:**

**Trading Model Optimization:**

**Chromosome:**
```
[indicator_period, entry_threshold, exit_threshold, stop_loss, 
 position_size, lookback_window, ma_type]
```

**Example:**
```
[14, 30, 70, 0.02, 0.1, 50, 'EMA']
RSI period=14, buy<30, sell>70, 2% stop loss, 10% position, 50-day lookback, EMA
```

**Fitness Function:**
```python
def fitness(chromosome):
    strategy = build_strategy(chromosome)
    results = backtest(strategy, historical_data)
    
    # Risk-adjusted return
    sharpe = results['sharpe_ratio']
    max_dd = results['max_drawdown']
    
    return sharpe - 0.5 * max_dd  # Penalize drawdown
```

**Critical Considerations:**

| Issue | Solution |
|-------|----------|
| **Overfitting** | Out-of-sample validation, walk-forward |
| **Look-ahead bias** | Strict data separation |
| **Transaction costs** | Include in fitness |
| **Survivorship bias** | Use complete historical data |

**Walk-Forward Optimization:**
```
Train on 2010-2015 → Test on 2016
Train on 2011-2016 → Test on 2017
...
Average performance across all test periods
```

**Multi-Objective:**
- Maximize: Sharpe ratio, total return
- Minimize: Max drawdown, volatility

**Caution:**
- GA can find strategies that worked historically but won't generalize
- Always use robust validation
- Consider transaction costs and slippage

---

## Question 28

**Describe recent advancements in hybrid genetic algorithms combining other AI techniques.**

**Answer:**

**Modern Hybrid Approaches:**

**1. GA + Deep Learning:**
- **Neuroevolution**: Evolve neural network architectures
- **Weight evolution**: GA for weights (gradient-free)
- **NEAT**: Evolve topology + weights together

**2. GA + Reinforcement Learning:**
- Evolve RL policies directly
- Evolve reward shaping parameters
- Population of agents for diverse exploration

**3. GA + Surrogate Models:**
```
Expensive fitness → Train surrogate model → Use surrogate for most evaluations
```
- Reduces computation dramatically
- Bayesian surrogates for uncertainty

**4. GA + Gradient Methods (Lamarckian):**
- GA for global search
- Gradient descent for local refinement
- Best of both worlds

**Recent Techniques:**

| Advancement | Description |
|-------------|-------------|
| **Quality-Diversity** | MAP-Elites, novelty search |
| **Population-based Training** | DeepMind's PBT for hyperparameters |
| **CMA-ES** | Covariance matrix adaptation |
| **Differential Evolution** | Better for continuous optimization |

**Quality-Diversity Example (MAP-Elites):**
- Not just find best solution
- Find best solution for each "behavior type"
- Diverse set of high-performing solutions

**Current Trends:**
- Learned operators (neural network suggests mutations)
- Self-adaptive parameters
- Integration with AutoML pipelines

**Interview Tip:**
Modern evolutionary computation is increasingly hybrid, combining evolutionary global search with learned local optimization.

---

## Question 29

**What is the significance of ‘multi-level selection’ in GAs?**

**Answer:** _[To be filled]_

---

## Question 30

**What are the advantages of using GAs forensemble model selection?**

**Answer:** _[To be filled]_

---

