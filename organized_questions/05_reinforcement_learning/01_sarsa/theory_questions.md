# SARSA - Theory Questions

## Question 1
**What does the acronym SARSA stand for?**

**Answer:** _To be filled_

---

## Question 2
**Explain the "on-policy" nature of SARSA.**

**Answer:** _To be filled_

---

## Question 3
**How is the SARSA update rule formulated mathematically?**

**Answer:** _To be filled_

---

## Question 4
**Compare SARSA and Q-Learning: what are the key differences?**

**Answer:** _To be filled_

---

## Question 5
**Describe the process of learning a policy using SARSA on a gridworld.**

**Answer:** _To be filled_

---

## Question 6
**When would SARSA be preferred over Q-Learning?**

**Answer:** _To be filled_

---

## Question 7
**What are the main steps in the SARSA algorithm?**

**Answer:** _To be filled_

---

## Question 8
**How do you select the next action in SARSA?**

**Answer:** _To be filled_

---

## Question 9
**What role does the learning rate (α) play in SARSA?**

**Answer:** _To be filled_

---

## Question 10
**What is the impact of a high discount factor (γ) in SARSA?**

**Answer:** _To be filled_

---

## Question 11
**How does SARSA handle the exploration-exploitation tradeoff?**

**Answer:** _To be filled_

---

## Question 12
**In which scenarios can SARSA perform worse than Q-Learning?**

**Answer:** _To be filled_

---

## Question 13
**How does on-policy learning affect convergence in SARSA?**

**Answer:** _To be filled_

---

## Question 14
**Explain the term "temporal difference" in SARSA.**

**Answer:** _To be filled_

---

## Question 15
**What is Eligibility Traces in the context of SARSA(λ)?**

**Answer:** _To be filled_

---

## Question 16
**How are rewards propagated in episodes using SARSA?**

**Answer:** _To be filled_

---

## Question 17
**How can SARSA be extended for continuous state and action spaces?**

**Answer:** _To be filled_

---

## Question 18
**What is the role of ε-greedy policy in SARSA?**

**Answer:** _To be filled_

---

## Question 19
**Provide an example of a real-world task suitable for SARSA.**

**Answer:** _To be filled_

---

## Question 20
**How does SARSA handle stochastic environments?**

**Answer:** _To be filled_

---

## Question 21
**What is SARSA(λ) and why is λ introduced?**

**Answer:** _To be filled_

---

## Question 22
**How do you initialize Q-values in SARSA?**

**Answer:** _To be filled_

---

## Question 23
**What is the effect of the initial Q-values on learning speed?**

**Answer:** _To be filled_

---

## Question 24
**How does Expected SARSA differ from regular SARSA?**

**Answer:** _To be filled_

---

## Question 25
**What are the benefits of Expected SARSA over SARSA?**

**Answer:** _To be filled_

---

## Question 26
**What is the computational complexity of SARSA per iteration?**

**Answer:** _To be filled_

---

## Question 27
**How would you implement SARSA for the Taxi-v3 environment?**

**Answer:** _To be filled_

---

## Question 28
**Explain why SARSA is considered an on-policy algorithm.**

**Answer:** _To be filled_

---

## Question 29
**How does batch updating work in SARSA?**

**Answer:** _To be filled_

---

## Question 30
**What is the policy improvement step in SARSA?**

**Answer:** _To be filled_

---

## Question 31
**Describe a scenario of policy evaluation in SARSA.**

**Answer:** _To be filled_

---

## Question 32
**How would you visualize the learning progress in SARSA?**

**Answer:** _To be filled_

---

## Question 33
**What challenges do you face in hyperparameter tuning for SARSA?**

**Answer:** _To be filled_

---

## Question 34
**How can function approximation be integrated with SARSA?**

**Answer:** _To be filled_

---

## Question 35
**What are the limitations of tabular SARSA?**

**Answer:** _To be filled_

---

## Question 36
**What makes SARSA robust to policy changes?**

**Answer:** _To be filled_

---

## Question 37
**How do terminal states affect updates in SARSA?**

**Answer:** _To be filled_

---

## Question 38
**Give an example of using decaying epsilon for exploration in SARSA.**

**Answer:** _To be filled_

---

## Question 39
**What are the theoretical convergence guarantees for SARSA?**

**Answer:** _To be filled_

---

## Question 40
**How does stochasticity in the environment dynamics affect SARSA learning?**

**Answer:** _To be filled_

---

## Question 41
**What is the practical impact of action stochasticity on SARSA's updates?**

**Answer:** _To be filled_

---

## Question 42
**Explain reward shaping with respect to SARSA.**

**Answer:** _To be filled_

---

## Question 43
**How do you modify SARSA for partially observable environments?**

**Answer:** _To be filled_

---

## Question 44
**What is the difference between Monte Carlo and SARSA methods?**

**Answer:** _To be filled_

---

## Question 45
**How can SARSA be used in multi-agent settings?**

**Answer:** _To be filled_

---

## Question 46
**Illustrate SARSA's performance in sparse reward environments.**

**Answer:** _To be filled_

---

## Question 47
**What role does delayed reward play in SARSA's learning curve?**

**Answer:** _To be filled_

---

## Question 48
**How do you adapt SARSA for continuous reward spaces?**

**Answer:** _To be filled_

---

## Question 49
**Describe applications where SARSA may underperform.**

**Answer:** _To be filled_

---

## Question 50
**What recent advancements or variants exist for the SARSA algorithm?**

**Answer:** _To be filled_

---
