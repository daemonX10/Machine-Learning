# Actor-Critic / A3C / PPO / TRPO - Theory Questions

## Question 1
**What is an Actor-Critic architecture?**

**Answer:** _To be filled_

---

## Question 2
**How does the actor-critic framework differ from pure policy gradients?**

**Answer:** _To be filled_

---

## Question 3
**What is the main advantage of A3C over traditional RL algorithms?**

**Answer:** _To be filled_

---

## Question 4
**How do multiple agents in A3C speed up learning?**

**Answer:** _To be filled_

---

## Question 5
**What is asynchronous updating in A3C?**

**Answer:** _To be filled_

---

## Question 6
**What does PPO stand for? How does it work?**

**Answer:** _To be filled_

---

## Question 7
**What problem does PPO solve in policy gradient methods?**

**Answer:** _To be filled_

---

## Question 8
**How does TRPO enforce trust regions?**

**Answer:** _To be filled_

---

## Question 9
**What are surrogate objective functions?**

**Answer:** _To be filled_

---

## Question 10
**What is the advantage function, and how is it estimated?**

**Answer:** _To be filled_

---

## Question 11
**What is the purpose of the critic in actor-critic methods?**

**Answer:** _To be filled_

---

## Question 12
**How can the bias-variance tradeoff be managed in actor-critic models?**

**Answer:** _To be filled_

---

## Question 13
**Compare PPO and TRPO: when would you use each?**

**Answer:** _To be filled_

---

## Question 14
**What role does entropy bonus play in actor-critic methods?**

**Answer:** _To be filled_

---

## Question 15
**How is experience replay handled in actor-critic approaches?**

**Answer:** _To be filled_

---

## Question 16
**How do actor-critic methods ensure stability?**

**Answer:** _To be filled_

---

## Question 17
**Describe synchronous vs. asynchronous actor-critic training.**

**Answer:** _To be filled_

---

## Question 18
**What is GAE(Î») and how is it used?**

**Answer:** _To be filled_

---

## Question 19
**What are the limitations of on-policy actor-critic methods?**

**Answer:** _To be filled_

---

## Question 20
**How is off-policy learning used in actor-critic variants?**

**Answer:** _To be filled_

---

## Question 21
**How do you implement clipping in PPO?**

**Answer:** _To be filled_

---

## Question 22
**What is the main benefit of parallel environments in RL?**

**Answer:** _To be filled_

---

## Question 23
**How are recurrent neural networks used in A3C?**

**Answer:** _To be filled_

---

## Question 24
**Why is PPO considered less sensitive to changes in hyperparameters?**

**Answer:** _To be filled_

---

## Question 25
**Describe a typical use case for PPO.**

**Answer:** _To be filled_

---

## Question 26
**How are policy updates constrained in TRPO?**

**Answer:** _To be filled_

---

## Question 27
**What are the main challenges in scaling actor-critic methods?**

**Answer:** _To be filled_

---

## Question 28
**How do you handle exploration in actor-critic models?**

**Answer:** _To be filled_

---

## Question 29
**What is shared parameterization in actor-critic networks?**

**Answer:** _To be filled_

---

## Question 30
**Describe sample efficiency in actor-critic approaches.**

**Answer:** _To be filled_

---

## Question 31
**What is the role of the advantage estimator in PPO?**

**Answer:** _To be filled_

---

## Question 32
**How do you prevent reward hacking in actor-critic RL?**

**Answer:** _To be filled_

---

## Question 33
**Describe how actor-critic methods are used in robotics.**

**Answer:** _To be filled_

---

## Question 34
**What is the computational cost of TRPO per update?**

**Answer:** _To be filled_

---

## Question 35
**How is the KL divergence used in PPO and TRPO?**

**Answer:** _To be filled_

---

## Question 36
**What are common pitfalls when implementing A3C from scratch?**

**Answer:** _To be filled_

---

## Question 37
**Explain transfer learning in the context of actor-critic RL.**

**Answer:** _To be filled_

---

## Question 38
**How is TRPO's constraint implemented mathematically?**

**Answer:** _To be filled_

---

## Question 39
**What are the main differences between A3C and DDPG?**

**Answer:** _To be filled_

---

## Question 40
**How are distributed systems applied in actor-critic training?**

**Answer:** _To be filled_

---

## Question 41
**What is stochasticity in policy outputs and why does it matter?**

**Answer:** _To be filled_

---

## Question 42
**How does actor-critic handle delayed rewards?**

**Answer:** _To be filled_

---

## Question 43
**In what ways can credit assignment be improved in actor-critic?**

**Answer:** _To be filled_

---

## Question 44
**How do you monitor convergence in actor-critic agents?**

**Answer:** _To be filled_

---

## Question 45
**Why might actor-critic methods be unstable?**

**Answer:** _To be filled_

---

## Question 46
**How can you regularize actor-critic models?**

**Answer:** _To be filled_

---

## Question 47
**How do you ensure reproducibility in actor-critic experiments?**

**Answer:** _To be filled_

---

## Question 48
**What are recent trends in actor-critic research?**

**Answer:** _To be filled_

---

## Question 49
**What are real-world applications of PPO and TRPO?**

**Answer:** _To be filled_

---

## Question 50
**How can actor-critic architectures be applied to multi-task RL?**

**Answer:** _To be filled_

---
