{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7f1cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8448728\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "list_comp = [ i**2 for i in range(1_000_000)]\n",
    "print(sys.getsizeof(list_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39375e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "gen_exp= (i**2 for i in range(1_000_000))\n",
    "print(sys.getsizeof(gen_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed70b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_data took 1.0011s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "def timing_decorator(func):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} took {end-start:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator\n",
    "def process_data(n):\n",
    "    time.sleep(1)\n",
    "    return \"done\"\n",
    "\n",
    "process_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67fa0cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "a = numpy.array([[1, 2], [3, 4]])\n",
    "b = numpy.array([[5, 6], [7, 8]])\n",
    "c = a @ b  \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab6e30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(X,y,learning_rate=0.01,epochs=1000):\n",
    "    \n",
    "    n_samples,n_features = X.shape\n",
    "    b = np.zeros((n_samples,1))\n",
    "    X_b = np.c_[b,X]\n",
    "    \n",
    "    weights = np.random.randn(n_features + 1) * 0.01\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        y_pred = X_b@weights\n",
    "        error = y-y_pred\n",
    "        gradient = - 2*(X_b.T@error)\n",
    "        weights = weights - learning_rate*(gradient)\n",
    "        \n",
    "        if epoch%100==0:\n",
    "            loss = np.mean(error**2)\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.0f}\")\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "223db1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 54\n",
      "Epoch 100: Loss = 4\n",
      "Epoch 200: Loss = 4\n",
      "Epoch 300: Loss = 4\n",
      "Epoch 400: Loss = 4\n",
      "Epoch 500: Loss = 4\n",
      "Epoch 600: Loss = 4\n",
      "Epoch 700: Loss = 4\n",
      "Epoch 800: Loss = 4\n",
      "Epoch 900: Loss = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01672572, 5.97003522])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = 2*np.random.rand(100,1)\n",
    "y = 4+3*X[:,0] + np.random.randn(100)*0.5\n",
    "gradient_descent(X,y,learning_rate=0.0001,epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed036dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_test_split(X,y,test_size=0.2,random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    test_count = int(n_samples * test_size)\n",
    "    test_indices = indices[:test_count]\n",
    "    train_indices = indices[test_count:]\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dc7877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.arange(100).reshape(50,2)\n",
    "y = np.arange(50)\n",
    "X_train,y_train,X_test,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f27ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for dataframes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:341\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     all_columns = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     21\u001b[39m preprocessor = ColumnTransformer(\n\u001b[32m     22\u001b[39m     transformers=[\n\u001b[32m     23\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m,numeric_transformer,numeric_features),\n\u001b[32m     24\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m,categorical_transformer,categorical_features)\n\u001b[32m     25\u001b[39m     ]\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m full_pipeline = Pipeline(steps=[\n\u001b[32m     29\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m,preprocessor),\n\u001b[32m     30\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclassifier \u001b[39m\u001b[33m'\u001b[39m,RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m))\n\u001b[32m     31\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mfull_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:654\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m     )\n\u001b[32m    653\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:588\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    582\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    583\u001b[39m     step_idx=step_idx,\n\u001b[32m    584\u001b[39m     step_params=routed_params[name],\n\u001b[32m    585\u001b[39m     all_params=raw_params,\n\u001b[32m    586\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\memory.py:312\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:1551\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1553\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1554\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1555\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:993\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    990\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_transformers()\n\u001b[32m    991\u001b[39m n_samples = _num_samples(X)\n\u001b[32m--> \u001b[39m\u001b[32m993\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_remainder(X)\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:552\u001b[39m, in \u001b[36mColumnTransformer._validate_column_callables\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    550\u001b[39m         columns = columns(X)\n\u001b[32m    551\u001b[39m     all_columns.append(columns)\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     transformer_to_input_indices[name] = \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28mself\u001b[39m._columns = all_columns\n\u001b[32m    555\u001b[39m \u001b[38;5;28mself\u001b[39m._transformer_to_input_indices = transformer_to_input_indices\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damod\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:343\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    341\u001b[39m     all_columns = X.columns\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    345\u001b[39m     )\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    347\u001b[39m     columns = [key]\n",
      "\u001b[31mValueError\u001b[39m: Specifying the columns using strings is only supported for dataframes."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "numeric_features = ['age','income']\n",
    "categorical_features = ['city','gender']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ('num',numeric_transformer,numeric_features),\n",
    "    ('cat',categorical_transformer,categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('classifier ',RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train,y_train)\n",
    "predications = full_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cb3ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "[[  1 100]\n",
      " [  2 200]\n",
      " [  3 300]\n",
      " [  4 400]\n",
      " [  5 500]]\n",
      "\n",
      "Scaled data (mean=0, std=1):\n",
      "[[-1.41421356 -1.41421356]\n",
      " [-0.70710678 -0.70710678]\n",
      " [ 0.          0.        ]\n",
      " [ 0.70710678  0.70710678]\n",
      " [ 1.41421356  1.41421356]]\n",
      "\n",
      "Mean of scaled: [0. 0.]\n",
      "Std of scaled: [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class StandardScaler:\n",
    "    def __init__(self) -> None:\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def fit(self,X):\n",
    "        self.mean = np.mean(X,axis=0)\n",
    "        self.std = np.std(X,axis=0)\n",
    "        self.std[self.std==0]=1\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return (X-self.mean)/self.std\n",
    "    \n",
    "    def fit_transform(self,X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "\n",
    "X = np.array([[1, 100], [2, 200], [3, 300], [4, 400], [5, 500]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Original data:\")\n",
    "print(X)\n",
    "print(\"\\nScaled data (mean=0, std=1):\")\n",
    "print(X_scaled)\n",
    "print(f\"\\nMean of scaled: {X_scaled.mean(axis=0)}\")\n",
    "print(f\"Std of scaled: {X_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32b7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([\"red\", \"blue\", \"green\", \"red\", \"green\", \"blue\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814dd541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.str_('blue'): 0, np.str_('green'): 1, np.str_('red'): 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cate=np.unique(colors)\n",
    "print({cat : idx for idx,cat in enumerate(cate)})\n",
    "\n",
    "n_samples= len(colors)\n",
    "n_cate = len(cate)\n",
    "\n",
    "np.zeros((n_samples,n_cate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "289adf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encoding(data):\n",
    "    \n",
    "    categories = np.unique(data)\n",
    "    n_samples = len(data)\n",
    "    n_categories = len(categories)\n",
    "    \n",
    "    cat_to_idx = {cat : idx for idx , cat in enumerate(categories)}\n",
    "    # creating 2d matrix of n_sample and n_categories\n",
    "    one_hot = np.zeros((n_samples,n_categories))\n",
    "    \n",
    "    for i , value in enumerate(data):\n",
    "        one_hot[i,cat_to_idx[value]]=1\n",
    "    \n",
    "    return one_hot,categories\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f2b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['blue' 'green' 'red']\n",
      "Original: ['red' 'blue' 'green' 'red' 'green' 'blue']\n",
      "Encoded:\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "encoded, categories = one_hot_encoding(colors)\n",
    "\n",
    "print(f\"Categories: {categories}\")\n",
    "print(f\"Original: {colors}\")\n",
    "print(f\"Encoded:\\n{encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7ec0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.80\n",
      "Precision: 0.80\n",
      "Recall:    0.80\n",
      "F1 Score:  2.40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def confusion_matrix_values(y_true,y_pred):\n",
    "    TP = np.sum((y_true==1) & (y_pred==1))\n",
    "    TN = np.sum((y_true==0)& (y_pred==0))\n",
    "    FP = np.sum((y_true==0) * (y_pred==1))\n",
    "    FN = np.sum((y_true==1) & (y_pred==0))\n",
    "    return TP,TN,FP,FN\n",
    "    \n",
    "def accuracy(y_true,y_pred):\n",
    "    TP, TN, FP, FN = confusion_matrix_values(y_true, y_pred)\n",
    "    return (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "def precision(y_true,y_pred):\n",
    "    TP, TN, FP, FN = confusion_matrix_values(y_true, y_pred)\n",
    "    if TP + FP==0:\n",
    "        return 0\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def recall(y_true,y_pred):\n",
    "    TP, TN, FP, FN = confusion_matrix_values(y_true, y_pred)\n",
    "    if TP+FN ==0:\n",
    "        return 0\n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def f1_score(y_true,y_pred):\n",
    "    prec = precision(y_true,y_pred)\n",
    "    rec = recall(y_true,y_pred)\n",
    "    return 2*(prec*rec)/prec+rec\n",
    "\n",
    "y_true = np.array([1, 1, 1, 0, 0, 0, 1, 0, 1, 0])\n",
    "y_pred = np.array([1, 1, 0, 0, 0, 1, 1, 0, 1, 0])\n",
    "\n",
    "print(f\"Accuracy:  {accuracy(y_true, y_pred):.2f}\")\n",
    "print(f\"Precision: {precision(y_true, y_pred):.2f}\")\n",
    "print(f\"Recall:    {recall(y_true, y_pred):.2f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_true, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4737030",
   "metadata": {},
   "source": [
    "# Remaining Only Kmeans and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf3f19ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cluster1 = np.random.randn(50,2) + [0,0]\n",
    "cluster2 = np.random.randn(50,2) +[5,5]\n",
    "cluster3 = np.random.randn(50,2) + [10,10]\n",
    "\n",
    "X = np.concat([cluster1,cluster2,cluster3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17b4ebca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.65489433,  4.76060117],\n",
       "       [-0.48929256,  1.05194748],\n",
       "       [11.36308822, 11.66607811]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = np.random.choice(150,3,replace=False)\n",
    "centroid = X[random_indices]\n",
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231981bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.13492308, 7.28438172, 9.39459547])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = np.zeros((150,3))\n",
    "for i in range(3):\n",
    "    distances[:,i] = np.linalg.norm(X-centroid[i],axis=1)\n",
    "distances.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3ccc8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.argmin(distances,axis=1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1eb74efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_centroid = np.zeros((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe447a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.93697746, 9.80740614])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_points.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d6acb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.36308822, 11.66607811],\n",
       "       [ 9.20353206, 12.52936857],\n",
       "       [10.76626154,  9.18474248],\n",
       "       [ 8.71759761, 10.22376266],\n",
       "       [10.44524799, 11.17447495],\n",
       "       [ 8.86487479, 10.55021531],\n",
       "       [ 9.18296003,  9.28548504],\n",
       "       [11.64473792,  8.81987358],\n",
       "       [ 8.9736643 , 10.52977457],\n",
       "       [10.21225153, 10.45853334],\n",
       "       [ 9.28710639,  9.85648994],\n",
       "       [ 8.9390107 ,  8.25612824],\n",
       "       [11.58062676, 10.06365464],\n",
       "       [ 9.69388844,  9.18206626],\n",
       "       [10.66358655, 10.1745084 ],\n",
       "       [11.46782868,  8.94464925],\n",
       "       [ 9.71574043,  8.01559833],\n",
       "       [10.2753883 ,  9.98852658],\n",
       "       [ 8.36519639, 10.583369  ],\n",
       "       [ 9.28605306, 10.7822217 ],\n",
       "       [ 9.81938459,  9.34324061],\n",
       "       [10.31037946,  8.25193257],\n",
       "       [ 8.13733071,  9.25475242],\n",
       "       [10.88114723,  9.8230507 ],\n",
       "       [ 7.75922188, 10.45244547],\n",
       "       [ 9.62779415,  9.16981073],\n",
       "       [ 9.32231644, 10.2439315 ],\n",
       "       [ 9.9488478 ,  9.77590563],\n",
       "       [10.4428218 ,  9.85452558],\n",
       "       [ 9.09940698,  9.43044112],\n",
       "       [11.13554007,  9.63774212],\n",
       "       [10.54308312, 10.31701098],\n",
       "       [ 8.82041817,  8.49747359],\n",
       "       [11.40971321,  7.92842117],\n",
       "       [ 9.41526654, 11.62063423],\n",
       "       [10.28388769,  9.06196504],\n",
       "       [ 9.96833281, 10.2681145 ],\n",
       "       [10.02588484, 10.42689338],\n",
       "       [11.0427529 ,  8.03814663],\n",
       "       [ 8.46225672, 10.83778441],\n",
       "       [ 9.79401575, 11.81853498],\n",
       "       [ 9.75540427, 10.67620103],\n",
       "       [ 8.76701718,  8.92397265],\n",
       "       [ 9.77107548,  9.81518214],\n",
       "       [ 9.61515776, 10.69693547],\n",
       "       [11.49041895,  9.07349857],\n",
       "       [12.15454633,  9.90382408],\n",
       "       [10.44280902,  9.17254215],\n",
       "       [11.27602387,  9.15689678],\n",
       "       [ 8.67797557,  8.62897596]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_points = X[labels==2]\n",
    "new_centroid[2]=cluster_points.mean(axis=0)\n",
    "cluster_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cdae03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = np.random.choice(150,3,replace=False)\n",
    "centroid = X[random_indices]\n",
    "new_centroid = np.zeros((3,2))\n",
    "new_centroid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eadbeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X,k=3,max_iters=100):\n",
    "    n_samples,n_features = X.shape\n",
    "    random_indices = np.random.choice(n_samples,k,replace=False)\n",
    "    centroid = X[random_indices]\n",
    "    labels = []\n",
    "    \n",
    "    for iteration in range(max_iters):\n",
    "        \n",
    "        distances = np.zeros((n_samples,k))\n",
    "        for i in range(k):\n",
    "            distances[:,i] = np.linalg.norm(X - centroid[i],axis=1)\n",
    "        \n",
    "        labels = np.argmin(distances,axis=1)\n",
    "        \n",
    "        new_centroid = np.zeros((k,n_features))\n",
    "        \n",
    "        for i in range(k):\n",
    "            cluster_points = X[labels==i]\n",
    "            if len(cluster_points)>0:\n",
    "                new_centroid[i] = np.mean(cluster_points,axis=0)\n",
    "            else:\n",
    "                new_centroid[i] = centroid[i]\n",
    "                \n",
    "        centroid = new_centroid\n",
    "    return labels,centroid\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c4f6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.93870493,  4.89988974],\n",
       "       [10.14108163, 10.151184  ],\n",
       "       [-0.40037473, -0.44505658]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster1 = np.random.randn(10,2) + [0,0]\n",
    "cluster2 = np.random.randn(10,2) + [5,5]\n",
    "cluster3 = np.random.randn(10,2) + [10,10]\n",
    "X = np.concat([cluster1,cluster2,cluster3])\n",
    "X.shape\n",
    "labels,centroid = kmeans(X,k=3)\n",
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b52b4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5ff3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_assignment(points, centroids):\n",
    "    \"\"\"\n",
    "    Assign each point to the nearest centroid.\n",
    "    \"\"\"\n",
    "    # Write code here\n",
    "    n_samples = len(points)\n",
    "    k = len(centroids)\n",
    "    distance = np.zeros((n_samples,k))\n",
    "    for i in range(k):\n",
    "        distance[:,i] = np.linalg.norm(points - centroids[i],axis=1)\n",
    "    labels = np.argmin(distance,axis=1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45f7a76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_assignment(X,centroids=centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6511a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_assignment(points, centroids):\n",
    "    \"\"\"\n",
    "    Assign each point to the nearest centroid.\n",
    "    \"\"\"\n",
    "    # Write code here\n",
    "    assignments = []\n",
    "    for point in points:\n",
    "        min_dist = float(\"inf\")\n",
    "        min_idx = 0\n",
    "\n",
    "        for idx , centroid in enumerate(centroids):\n",
    "            distance = 0\n",
    "            for dim in range(len(point)):\n",
    "                distance+= (point[dim] - centroid[dim])**2\n",
    "            if distance <min_dist:\n",
    "                min_dist = distance\n",
    "                min_idx = idx\n",
    "        assignments.append(min_idx)\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc089e58",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
